{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trial0_ATE_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tomawock/NLP_Attack/blob/main/model/trial0_ATE_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRFaXYA3ttqc"
      },
      "source": [
        "### Caricamento Dipendenze "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDTxZNnpMpha",
        "outputId": "5b40cfad-d0f8-4811-fb99-93bcc2e6c7c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXxaHXN1K8Sx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upSUyaySxE36"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-BZeFloM9Dq"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ9Kg6ZBM-7v"
      },
      "source": [
        "test = pd.read_json('/content/drive/Shareddrives/Deep Learning/datasets/ATE_ABSITA/ATE_ABSITA_test_set/ate_absita_gold.ndjson'\n",
        "                       , lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbhv62DrXkvL"
      },
      "source": [
        "train = pd.read_json('/content/drive/Shareddrives/Deep Learning/datasets/ATE_ABSITA/ATE_ABSITA_training_set/ate_absita_training.ndjson'\n",
        "                       , lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "5WY0bqnZXtee",
        "outputId": "fb47dfe3-6317-45ec-d371-ee3c33a8755d"
      },
      "source": [
        "train.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>id_sentence</th>\n",
              "      <th>score</th>\n",
              "      <th>polarities</th>\n",
              "      <th>aspects_position</th>\n",
              "      <th>aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ottimo prodotto di marca, la qualità é veramen...</td>\n",
              "      <td>4b7254a1-3f31-4143-ab22-a8558aa4a73b</td>\n",
              "      <td>5</td>\n",
              "      <td>[[0, 0], [0, 1], [1, 0]]</td>\n",
              "      <td>[[120, 142], [71, 79], [29, 36]]</td>\n",
              "      <td>[provvisto di una tasca, capiente, qualità]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ottimo rasoio dal semplice utilizzo. Rade molt...</td>\n",
              "      <td>4b74d99d-891f-4526-bbd3-549fa244cd1c</td>\n",
              "      <td>5</td>\n",
              "      <td>[[1, 0], [1, 0], [1, 0], [1, 0]]</td>\n",
              "      <td>[[18, 26], [37, 41], [79, 86], [99, 105]]</td>\n",
              "      <td>[semplice, Rade, Pratico, pulire]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Un quarto delle dimensioni dello Show original...</td>\n",
              "      <td>4b7ff44f-fa9f-4ef0-97c8-e295e70ccc9b</td>\n",
              "      <td>5</td>\n",
              "      <td>[[1, 0], [1, 0], [1, 0], [0, 0]]</td>\n",
              "      <td>[[118, 132], [51, 62], [65, 70], [16, 26]]</td>\n",
              "      <td>[modalità notte, prestazioni, suono, dimensioni]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  ...                                           aspects\n",
              "0  Ottimo prodotto di marca, la qualità é veramen...  ...       [provvisto di una tasca, capiente, qualità]\n",
              "1  Ottimo rasoio dal semplice utilizzo. Rade molt...  ...                 [semplice, Rade, Pratico, pulire]\n",
              "2  Un quarto delle dimensioni dello Show original...  ...  [modalità notte, prestazioni, suono, dimensioni]\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mjOG8VpaeWu",
        "outputId": "e5b2e0d5-c907-4d65-f1ca-2c96f0e23ba5"
      },
      "source": [
        "print(test.columns)\n",
        "print(train.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['sentence', 'id_sentence', 'score', 'polarities', 'aspects_position',\n",
            "       'aspects'],\n",
            "      dtype='object')\n",
            "Index(['sentence', 'id_sentence', 'score', 'polarities', 'aspects_position',\n",
            "       'aspects'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb6duFp6NSsl",
        "outputId": "64ff3d4b-16aa-4aae-dea4-179bede75030"
      },
      "source": [
        "train.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "test.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "print(f'Contains {len(train)} sentences')\n",
        "print(f'Contains {len(test)} sentences')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contains 3054 sentences\n",
            "Contains 1200 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hju8aFRPUNl"
      },
      "source": [
        "Creazione colonna Positivi/Negativi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nXKH3OhN-Jd"
      },
      "source": [
        "train[\"review_type\"] = train[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "test[\"review_type\"] = test[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bQI-kjaOLEt",
        "outputId": "4228f51e-85a2-4ce8-afec-d131099442ec"
      },
      "source": [
        "print(f'TRAIN::\\n{train.review_type.value_counts()}')\n",
        "print(f'TEST::\\n{test.review_type.value_counts()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN::\n",
            "pos    2150\n",
            "neg     904\n",
            "Name: review_type, dtype: int64\n",
            "TEST::\n",
            "pos    857\n",
            "neg    343\n",
            "Name: review_type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8maG0Wcup5L"
      },
      "source": [
        "Rimozione Colonna Score in quanto non piu significativa per la Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEKPlbZKOR2D"
      },
      "source": [
        "train.drop(columns=['score'], inplace=True)\n",
        "test.drop(columns=['score'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWOE4X9sGDkA"
      },
      "source": [
        "with open(\"/content/drive/Shareddrives/Deep Learning/datasets/ATE_ABSITA/index2word.pkl\", 'rb') as output:\n",
        "  i2w = pickle.load(output)\n",
        "with open(\"/content/drive/Shareddrives/Deep Learning/datasets/ATE_ABSITA/word2index.pkl\", 'rb') as output:\n",
        "  w2i = pickle.load(output)\n",
        "with open(\"/content/drive/Shareddrives/Deep Learning/datasets/ATE_ABSITA/embedding_matrix.pkl\", 'rb') as output:\n",
        "  embedding_matrix = pickle.load(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSXceNfmLsPj"
      },
      "source": [
        "Trasformazione input da frasi a vettori di parole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlsXwlXxKO-6"
      },
      "source": [
        "def my_text_to_word_sequence(sentence):\n",
        "  return keras.preprocessing.text.text_to_word_sequence(sentence,\n",
        "                                                        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`\\'{|}~\\t\\n',\n",
        "                                                        lower=True)\n",
        "\n",
        "sentences = [my_text_to_word_sequence(sentence) for sentence in train['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Tt7w0eUPCkx"
      },
      "source": [
        "Trova la frase più lunga"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud1amA0ONiKB"
      },
      "source": [
        "max_index, max = (-1, -1)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P17F0qxvvWnK"
      },
      "source": [
        "### Creazione dataset con word_embedding\n",
        "Padding fino a **`max`** ovvero la dimensione massima delle frasi ottenuto alla creazione dell'array di numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faTkcVq0Q-Ij"
      },
      "source": [
        "embedded_trainset = np.zeros(shape=(len(sentences), max, 300))\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_trainset[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW6FAgnbabtE"
      },
      "source": [
        "one_hot_train = tf.convert_to_tensor(\n",
        "    OneHotEncoder(sparse=False).fit_transform(\n",
        "        train.review_type.to_numpy().reshape(-1, 1)\n",
        "        )\n",
        "    )\n",
        "\n",
        "one_hot_test = OneHotEncoder(sparse=False).fit_transform(\n",
        "  test.review_type.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxt3Vrs2LZg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1f6b66-3da4-4be5-97e5-0284a8c27d82"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Input(shape=(max, 300)))\n",
        "model.add(keras.layers.LSTM(64, recurrent_dropout=0.2))  # keras.layers.GRU prova\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 93,570\n",
            "Trainable params: 93,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQEP7Za6w84_"
      },
      "source": [
        "Trasformazione **y** in tensore, in modo tale da trasformare pos in [0,1] e neg in [1,0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Z8HN44LybB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07f3831-e3e0-4d4a-99da-9c287ae30dc8"
      },
      "source": [
        "result = model.fit(embedded_trainset, one_hot_train, epochs=2, batch_size=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "123/123 [==============================] - 7s 58ms/step - loss: 0.6078 - accuracy: 0.7046\n",
            "Epoch 2/2\n",
            "123/123 [==============================] - 7s 61ms/step - loss: 0.6075 - accuracy: 0.7046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b4RdBj4ZLoH"
      },
      "source": [
        "# OTTIMIZZAZIONE CON OPTUNA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktY7eHXzZPYe"
      },
      "source": [
        "%pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poNeE0cfZbqr"
      },
      "source": [
        "import optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JEM_d5RZYRS"
      },
      "source": [
        "def objective(trial):\n",
        "  units = trial.suggest_int('units', 40, 140)\n",
        "  recurrent_dropout = trial.suggest_float('dropout', 0.2, 0.8, step=0.01)\n",
        "\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Input(shape=(max, 300)))\n",
        "  model.add(keras.layers.Bidirectional(layer=keras.layers.LSTM(units=units,\n",
        "                                                                 recurrent_dropout=recurrent_dropout,\n",
        "                                                                 activation='tanh')))\n",
        "  model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.Adam(0.001),\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  batch_size = trial.suggest_int('batch_size', 50, 128)\n",
        "  result = model.fit(embedded_trainset,\n",
        "                     one_hot_train,\n",
        "                     epochs=100,\n",
        "                     batch_size=batch_size,\n",
        "                     callbacks=[keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                                patience=10)]))\n",
        "  \n",
        "\n",
        "  return model.evaluate(embedded_trainset, one_hot_train)[1]\n",
        "    \n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr4SGOnGGqyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7263040-f7fc-4edf-99b8-85a39f135d43"
      },
      "source": [
        "study = optuna.create_study(direction='maximize',storage=\"sqlite:///models.db\", study_name=\"ATE\")\n",
        "study.optimize(objective, n_trials=300, n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-01-26 16:52:57,099]\u001b[0m A new study created in memory with name: no-name-1dacc06a-777e-4e9f-ad9b-00d271fdf01c\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_PlXMj2nm0M"
      },
      "source": [
        "study.trials_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}