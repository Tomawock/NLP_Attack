{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ATE_studio_0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMyO6M9m8IHnYJchl7kIimM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tomawock/NLP_Attack/blob/main/evaluate_models/ATE_studio_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh-DWn9G8qo3",
        "outputId": "bb115088-4043-4e05-e8ad-f0219bf4df56"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhZgkl4B_XVu",
        "outputId": "98ce97ed-fb9c-46fb-e2a5-a3699e52d134"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/88/9c53460b97c61bce926dfe9dce51e4887c283416ff89ed30af0b73f44efa/optuna-2.5.0-py3-none-any.whl (287kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 15.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30kB 12.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 102kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 112kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 122kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 133kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 153kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 163kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 174kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 184kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 194kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 204kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 215kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 225kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 235kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 245kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 256kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 266kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 276kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from optuna) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.3.23)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/07/799a76aca0acd406e3259cc6c558ca1cdadf88250953b6c8105b421a9e33/alembic-1.5.5.tar.gz (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/d6/7d9acb68a77acd140be7fececb7f2701b2a29d2da9c54184cb8f93509590/cliff-3.7.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/39/0230290df0519d528d8d0ffdfd900150ed24e0076d13b1f19e279444aab1/colorlog-4.7.2-py2.py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/db/2d2d88b924aa4674a080aae83b59ea19d593250bfe5ed789947c21736785/Mako-1.1.4.tar.gz (479kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 26.8MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/15061b32332bb35ea2a2f6263d0f616779d576e82739ec8e7fcf3c94abf5/cmd2-1.5.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 32.0MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 34.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.0.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff->optuna) (53.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2>=1.0.0->cliff->optuna) (3.4.0)\n",
            "Building wheels for collected packages: alembic, Mako, pyperclip\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.5.5-py2.py3-none-any.whl size=156597 sha256=93bdd24e2bd6a3b432d8b7b2d28fd2ce758a526d6f590dbf78f35cbab9988593\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/3f/61/7de6e3cef766d2680a5d81b1a388286e640f6a681eb589d643\n",
            "  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Mako: filename=Mako-1.1.4-py2.py3-none-any.whl size=75675 sha256=5aff7c646cdcdb83ba5b85cf984e2dfe8e1ee389399a3288e360ccaf7f3122fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/10/d3/aeb26e20d19045e2a68e5d3cbb57432e11b5d9c92c99f98d47\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11107 sha256=259101e34ebf02e9142cf73efe09c5822e5d3f989d555d99e4cc68d28fc5acdd\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built alembic Mako pyperclip\n",
            "Installing collected packages: Mako, python-editor, alembic, colorama, pyperclip, cmd2, pbr, stevedore, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.5.5 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-4.7.2 optuna-2.5.0 pbr-5.5.1 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvIOj4268c1y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9omR98sh9v-r"
      },
      "source": [
        "path=\"/content/drive/Shareddrives/Deep Learning/datasets/ATE_ABSITA/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPJoY-GO8suc"
      },
      "source": [
        "test = pd.read_json(path+'ATE_ABSITA_test_set/ate_absita_gold.ndjson'\n",
        "                       , lines=True)\n",
        "\n",
        "train = pd.read_json(path+'ATE_ABSITA_training_set/ate_absita_training.ndjson'\n",
        "                       , lines=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1OCMqGV8szX",
        "outputId": "31dd46c6-dd61-4ce9-f905-c3834a286f4c"
      },
      "source": [
        "print(test.columns)\n",
        "print(train.columns)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['sentence', 'id_sentence', 'score', 'polarities', 'aspects_position',\n",
            "       'aspects'],\n",
            "      dtype='object')\n",
            "Index(['sentence', 'id_sentence', 'score', 'polarities', 'aspects_position',\n",
            "       'aspects'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbAHXJR78s3W",
        "outputId": "298b4461-2819-4c66-d045-62fe2bbd74d2"
      },
      "source": [
        "train.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "test.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "print(f'Contains {len(train)} sentences')\n",
        "print(f'Contains {len(test)} sentences')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contains 3054 sentences\n",
            "Contains 1200 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iePD6n9p82nG"
      },
      "source": [
        "Creazione colonna Positivi/Negativi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuCtCXCw8s6M",
        "outputId": "5f8661d5-b448-44e5-b569-b0905f1581fa"
      },
      "source": [
        "train[\"review_type\"] = train[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "test[\"review_type\"] = test[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "\n",
        "print(f'TRAIN::\\n{train.review_type.value_counts()}')\n",
        "print(f'TEST::\\n{test.review_type.value_counts()}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN::\n",
            "pos    2150\n",
            "neg     904\n",
            "Name: review_type, dtype: int64\n",
            "TEST::\n",
            "pos    857\n",
            "neg    343\n",
            "Name: review_type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru-WHUt788NG"
      },
      "source": [
        "Rimozione Colonna Score in quanto non piu significativa per la Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqPpoik2AJJZ"
      },
      "source": [
        "train.drop(columns=['score'], inplace=True)\n",
        "test.drop(columns=['score'], inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTQldsfF8s8_"
      },
      "source": [
        "with open(path+\"word2index.pkl\", 'rb') as output:\n",
        "  w2i = pickle.load(output)\n",
        "with open(path+\"embedding_matrix.pkl\", 'rb') as output:\n",
        "  embedding_matrix = pickle.load(output)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21BASbk79EIe"
      },
      "source": [
        "Trasformazione input da frasi a vettori di parole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv5nfe958s_s"
      },
      "source": [
        "def my_text_to_word_sequence(sentence):\n",
        "  return keras.preprocessing.text.text_to_word_sequence(sentence,\n",
        "                                                        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`\\'{|}~\\t\\n',\n",
        "                                                        lower=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHcjEZ6j9g_F"
      },
      "source": [
        "TRAIN, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lPd3qFfAqJl"
      },
      "source": [
        "one_hot_train = OneHotEncoder(sparse=False).fit_transform(\n",
        "        train.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_bOaNrp5-9b"
      },
      "source": [
        "sentences = [my_text_to_word_sequence(sentence) for sentence in train['sentence']]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeTE81j_9cOv"
      },
      "source": [
        "Estrai la massima dimensione dell'input in base ai vari dataset considerati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pudlFdxF8tCA",
        "outputId": "28d432a6-c7c6-4436-9d28-ccf23fa05ddb"
      },
      "source": [
        "max_index, max = (-1, -1)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "\n",
        "print(f'Il massimo è {max}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il massimo è 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbKTvQuOEaP3"
      },
      "source": [
        "Crao i vari embedding per tutti i dataset, quest'operazione e pesante "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfA2XQzE9hdL"
      },
      "source": [
        "embedded_trainset = np.zeros(shape=(len(sentences), max, 300))\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_trainset[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5rb4COz9oVn"
      },
      "source": [
        "Modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IHhcxg49qg5"
      },
      "source": [
        "best_params = optuna.load_study(study_name=\"ATE\", storage=\"sqlite:///\"+path+\"optuna_ATE_studio_0.db\").best_params"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM6k1Bf08TJ3",
        "outputId": "3921edbc-5fb9-493b-e298-6dabe9f86f85"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Input(shape=(max, 300)))\n",
        "model.add(keras.layers.Bidirectional(layer=keras.layers.LSTM(units=best_params[\"units\"],\n",
        "                                                             recurrent_dropout=best_params[\"dropout\"],\n",
        "                                                             activation='tanh')))\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=keras.optimizers.Adam(0.001),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8t68xO9BMmb"
      },
      "source": [
        "#train model\n",
        "result = model.fit(embedded_trainset,\n",
        "                 one_hot_train,\n",
        "                 epochs=100,\n",
        "                 batch_size=best_params[\"batch_size\"],\n",
        "                 callbacks=[keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                            patience=10)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbstjV0B9qmF"
      },
      "source": [
        "#save the model\n",
        "model.save_weights(path+'ATE_w_studio_0.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmdfbdbGBQMT"
      },
      "source": [
        "#load only the w of the model, the model must be already executed\n",
        "model.load_weights(path+'ATE_w_studio_0_lorenzo.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Y6MEPfCRC-"
      },
      "source": [
        "EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hbNPFC_Bjfd"
      },
      "source": [
        "model.evaluate(embedded_trainset,one_hot_train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}