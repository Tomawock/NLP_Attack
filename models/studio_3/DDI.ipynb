{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tomawock/NLP_Attack/blob/main/models/studio_3/DDI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiMkeY5Y_NZv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQcpBBopuQnf"
      },
      "source": [
        "!pip install optuna "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAgxUDSD-0pM"
      },
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow import keras\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvIuSdIzxK40"
      },
      "source": [
        "path=\"Desktop\\\\DDI\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Jt8EmX-IBe"
      },
      "source": [
        "path=\"/content/drive/Shareddrives/Deep Learning/datasets/DDI/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcgM45TxuiWB"
      },
      "source": [
        "PATH PER WINDOWDS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm8p2lwD_F5T"
      },
      "source": [
        "dev = pd.read_csv(path+'\\ddi2013-type\\\\dev.tsv', sep='\\t')\n",
        "test = pd.read_csv(path+'\\ddi2013-type\\\\test.tsv', sep='\\t')\n",
        "train = pd.read_csv(path+'\\ddi2013-type\\\\train.tsv', sep='\\t')\n",
        "\n",
        "data_sinonimi = pd.read_csv(path+\"\\ddi2013-type\\\\DDI_sinonimi_test.csv\")\n",
        "data_embedding = pd.read_csv(path+\"\\ddi2013-type\\\\DDI_embedding_test.csv\")\n",
        "\n",
        "data_embedding_train = pd.read_csv(path+\"\\ddi2013-type\\\\DDI_embedding.csv\")\n",
        "data_sinonimi_train = pd.read_csv(path+\"\\ddi2013-type\\\\DDI_sinonimi.csv\")\n",
        "\n",
        "print(test.shape)\n",
        "print(data_sinonimi.shape)\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw74BJhOugRM"
      },
      "source": [
        "dev = pd.read_csv(path+'ddi2013-type/dev.tsv', sep='\\t')\n",
        "test = pd.read_csv(path+'ddi2013-type/test.tsv', sep='\\t')\n",
        "train = pd.read_csv(path+'ddi2013-type/train.tsv', sep='\\t')\n",
        "\n",
        "data_sinonimi = pd.read_csv(path+\"ddi2013-type/DDI_sinonimi_test.csv\")\n",
        "data_embedding = pd.read_csv(path+\"ddi2013-type/DDI_embedding_test.csv\")\n",
        "\n",
        "data_embedding_train = pd.read_csv(path+\"ddi2013-type/DDI_embedding.csv\")\n",
        "\n",
        "print(test.shape)\n",
        "print(data_sinonimi.shape)\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YODJXjNIDjOL"
      },
      "source": [
        "test_study_1 = pd.concat([data_sinonimi, data_embedding, test], ignore_index=True)\n",
        "train_study_1 = pd.concat([data_sinonimi_train, data_embedding_train, train], ignore_index=True)\n",
        "print (test_study_1.shape)\n",
        "print (train_study_1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdpEzJH3AAwb"
      },
      "source": [
        "print(train.shape)\n",
        "print(data_sinonimi.shape)\n",
        "print(data_embedding.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxqcDbYlANrk"
      },
      "source": [
        "print(train.label.value_counts())\n",
        "print(data_sinonimi.label.value_counts())\n",
        "print(data_embedding.label.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx5Dywe8E8gx"
      },
      "source": [
        "with open(path+\"\\word2index.pkl\", 'rb') as output:\n",
        "  w2i = pickle.load(output)\n",
        "with open(path+\"\\embedding_matrix.pkl\", 'rb') as output:\n",
        "  embedding_matrix = pickle.load(output)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv-nI15mvf4N"
      },
      "source": [
        "Set up per allenamento Modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUcRaXI_5f5i"
      },
      "source": [
        "categories = [['DDI-false', 'DDI-mechanism', 'DDI-effect', 'DDI-advise','DDI-int']]\n",
        "\n",
        "my_text_to_word_sequence = lambda sen: keras.preprocessing.text.text_to_word_sequence(sen,\n",
        "                                                                                      filters='!\"#&()*+,-./:;<=>?[\\\\]^_`\\'{|}~\\t\\n',\n",
        "                                                                                      lower=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ_NP5DJ5iDf"
      },
      "source": [
        "TRAINSET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AQtVajZE_Nv"
      },
      "source": [
        "five_hot_train = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  train_study_1.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ7yUd9tFEV6"
      },
      "source": [
        "sentences_train = [my_text_to_word_sequence(sentence) for sentence in train_study_1['sentence']]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpyi_R0QM9yO"
      },
      "source": [
        "TESTSET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_bOaNrp5-9b"
      },
      "source": [
        "five_hot_test = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  test_study_1.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtLEyoQX6BME"
      },
      "source": [
        "sentences_test = [my_text_to_word_sequence(sentence) for sentence in test_study_1['sentence']]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ylB78veIsv_"
      },
      "source": [
        "ORIGINALE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nViSudaIqQl"
      },
      "source": [
        "five_hot_orig = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  test.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znIsuAiwIyqd"
      },
      "source": [
        "sentences_orig = [my_text_to_word_sequence(sentence) for sentence in test['sentence']]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP9Ku4JjM_4D"
      },
      "source": [
        "SINONIMI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F46YcI6F6DEP"
      },
      "source": [
        "five_hot_sin = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  data_sinonimi.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPjA_DfR6DWX"
      },
      "source": [
        "sentences_sin = [my_text_to_word_sequence(sentence) for sentence in data_sinonimi['sentence']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw5TZ84dNdNs"
      },
      "source": [
        "EMBEDDING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwCdjTJ-6K6x"
      },
      "source": [
        "five_hot_emb = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  data_embedding.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOzh1rcV6LEl"
      },
      "source": [
        "sentences_emb = [my_text_to_word_sequence(sentence) for sentence in data_embedding['sentence']]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBbI74mh5Vs_"
      },
      "source": [
        "Estrai la massima dimensione dell'input in base ai vari dataset considerati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP3eoSK35U8J",
        "outputId": "970ed749-48e7-4d9d-d005-6ca644a76083",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_index, max = (-1, -1)\n",
        "for i, sentence in enumerate(sentences_train):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_orig):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "  \n",
        "print(f'Il massimo è {max}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il massimo è 92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEM1DpJEGtd"
      },
      "source": [
        "Crao i vari embedding per tutti i dataset, quest'operazione e pesante "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU4vzy2XFMNw"
      },
      "source": [
        "embedded_trainset = np.zeros(shape=(len(sentences_train), max, 300))\n",
        "for i, sentence in enumerate(sentences_train):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_trainset[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcTLLtVaT_3x"
      },
      "source": [
        "embedded_origin = np.zeros(shape=(len(sentences_orig), max, 300))\n",
        "for i, sentence in enumerate(sentences_orig):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_origin[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzIOhX8XMGS8"
      },
      "source": [
        "embedded_testset = np.zeros(shape=(len(sentences_test), max, 300))\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_testset[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-G-eEVMM_gB"
      },
      "source": [
        "embedded_sin = np.zeros(shape=(len(sentences_sin), max, 300))\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_sin[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR8cp_siNfYB"
      },
      "source": [
        "embedded_emb = np.zeros(shape=(len(sentences_emb), max, 300))\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_emb[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG87uMvKvm0L"
      },
      "source": [
        "Carica optuna results e inizializza il modello, oppure salva il modello oppure carica solo i pesi del modello "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b16mA7IuBRrK"
      },
      "source": [
        "best_params = optuna.load_study(study_name=\"DDI\", storage=\"sqlite:///\"+path+\"\\ddi2013-type\\\\optuna_ddi_studio_0.db\").best_params"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMwRMnYDCMSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb51afbd-dd95-46da-81c9-a1ee00769944"
      },
      "source": [
        "print(f'{best_params}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 89, 'dropout': 0.63, 'units': 81}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVMfBNRxCuy6"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Input(shape=(max, 300)))\n",
        "model.add(keras.layers.Bidirectional(layer=keras.layers.LSTM(units=best_params['units'],\n",
        "                                                             recurrent_dropout=best_params['dropout'],\n",
        "                                                             activation='tanh')))\n",
        "\n",
        "model.add(keras.layers.Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxDADamsukZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d754d69-21e2-4e42-d9a7-10d7e8747ee1"
      },
      "source": [
        "#train the model\n",
        "result = model.fit(embedded_trainset,\n",
        "                   five_hot_train,\n",
        "                   epochs=100,\n",
        "                   batch_size=best_params['batch_size'],\n",
        "                   callbacks=[keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                            patience=10)])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "633/633 [==============================] - 137s 216ms/step - loss: 0.5420 - accuracy: 0.8422\n",
            "Epoch 2/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.4382 - accuracy: 0.8456\n",
            "Epoch 3/100\n",
            "633/633 [==============================] - 138s 218ms/step - loss: 0.4003 - accuracy: 0.8498\n",
            "Epoch 4/100\n",
            "633/633 [==============================] - 139s 220ms/step - loss: 0.3754 - accuracy: 0.8541\n",
            "Epoch 5/100\n",
            "633/633 [==============================] - 140s 221ms/step - loss: 0.3569 - accuracy: 0.8578\n",
            "Epoch 6/100\n",
            "633/633 [==============================] - 142s 224ms/step - loss: 0.3387 - accuracy: 0.8637\n",
            "Epoch 7/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.3232 - accuracy: 0.8684\n",
            "Epoch 8/100\n",
            "633/633 [==============================] - 141s 222ms/step - loss: 0.3069 - accuracy: 0.8742\n",
            "Epoch 9/100\n",
            "633/633 [==============================] - 141s 222ms/step - loss: 0.2940 - accuracy: 0.8792\n",
            "Epoch 10/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.2822 - accuracy: 0.8836\n",
            "Epoch 11/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.2702 - accuracy: 0.8891\n",
            "Epoch 12/100\n",
            "633/633 [==============================] - 141s 222ms/step - loss: 0.2621 - accuracy: 0.8919\n",
            "Epoch 13/100\n",
            "633/633 [==============================] - 141s 222ms/step - loss: 0.2524 - accuracy: 0.8970\n",
            "Epoch 14/100\n",
            "633/633 [==============================] - 140s 221ms/step - loss: 0.2463 - accuracy: 0.9000\n",
            "Epoch 15/100\n",
            "633/633 [==============================] - 140s 222ms/step - loss: 0.2384 - accuracy: 0.9024\n",
            "Epoch 16/100\n",
            "633/633 [==============================] - 141s 224ms/step - loss: 0.2302 - accuracy: 0.9051\n",
            "Epoch 17/100\n",
            "633/633 [==============================] - 140s 222ms/step - loss: 0.2244 - accuracy: 0.9083\n",
            "Epoch 18/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.2173 - accuracy: 0.9104\n",
            "Epoch 19/100\n",
            "633/633 [==============================] - 141s 222ms/step - loss: 0.2142 - accuracy: 0.9120\n",
            "Epoch 20/100\n",
            "633/633 [==============================] - 140s 221ms/step - loss: 0.2091 - accuracy: 0.9145\n",
            "Epoch 21/100\n",
            "633/633 [==============================] - 140s 221ms/step - loss: 0.2006 - accuracy: 0.9188\n",
            "Epoch 22/100\n",
            "633/633 [==============================] - 139s 220ms/step - loss: 0.1969 - accuracy: 0.9199\n",
            "Epoch 23/100\n",
            "633/633 [==============================] - 139s 220ms/step - loss: 0.1922 - accuracy: 0.9222\n",
            "Epoch 24/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.1879 - accuracy: 0.9237\n",
            "Epoch 25/100\n",
            "633/633 [==============================] - 142s 225ms/step - loss: 0.1829 - accuracy: 0.9264\n",
            "Epoch 26/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.1789 - accuracy: 0.9283\n",
            "Epoch 27/100\n",
            "633/633 [==============================] - 139s 220ms/step - loss: 0.1753 - accuracy: 0.9278\n",
            "Epoch 28/100\n",
            "633/633 [==============================] - 140s 221ms/step - loss: 0.1741 - accuracy: 0.9294\n",
            "Epoch 29/100\n",
            "633/633 [==============================] - 140s 221ms/step - loss: 0.1679 - accuracy: 0.9330\n",
            "Epoch 30/100\n",
            "633/633 [==============================] - 140s 222ms/step - loss: 0.1663 - accuracy: 0.9333\n",
            "Epoch 31/100\n",
            "633/633 [==============================] - 140s 222ms/step - loss: 0.1615 - accuracy: 0.9353\n",
            "Epoch 32/100\n",
            "633/633 [==============================] - 142s 225ms/step - loss: 0.1596 - accuracy: 0.9356\n",
            "Epoch 33/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.1565 - accuracy: 0.9366\n",
            "Epoch 34/100\n",
            "633/633 [==============================] - 142s 225ms/step - loss: 0.1544 - accuracy: 0.9382\n",
            "Epoch 35/100\n",
            "633/633 [==============================] - 143s 225ms/step - loss: 0.1507 - accuracy: 0.9399\n",
            "Epoch 36/100\n",
            "633/633 [==============================] - 142s 224ms/step - loss: 0.1474 - accuracy: 0.9418\n",
            "Epoch 37/100\n",
            "633/633 [==============================] - 142s 224ms/step - loss: 0.1458 - accuracy: 0.9428\n",
            "Epoch 38/100\n",
            "633/633 [==============================] - 142s 224ms/step - loss: 0.1439 - accuracy: 0.9429\n",
            "Epoch 39/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.1392 - accuracy: 0.9444\n",
            "Epoch 40/100\n",
            "633/633 [==============================] - 142s 225ms/step - loss: 0.1395 - accuracy: 0.9447\n",
            "Epoch 41/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.1341 - accuracy: 0.9477\n",
            "Epoch 42/100\n",
            "633/633 [==============================] - 141s 223ms/step - loss: 0.1334 - accuracy: 0.9484\n",
            "Epoch 43/100\n",
            "633/633 [==============================] - 142s 224ms/step - loss: 0.1316 - accuracy: 0.9477\n",
            "Epoch 44/100\n",
            "633/633 [==============================] - 142s 225ms/step - loss: 0.1270 - accuracy: 0.9502\n",
            "Epoch 45/100\n",
            "633/633 [==============================] - 143s 225ms/step - loss: 0.1274 - accuracy: 0.9497\n",
            "Epoch 46/100\n",
            "633/633 [==============================] - 142s 225ms/step - loss: 0.1265 - accuracy: 0.9510\n",
            "Epoch 47/100\n",
            "633/633 [==============================] - 142s 224ms/step - loss: 0.1242 - accuracy: 0.9518\n",
            "Epoch 48/100\n",
            "633/633 [==============================] - 142s 224ms/step - loss: 0.1208 - accuracy: 0.9531\n",
            "Epoch 49/100\n",
            "633/633 [==============================] - 142s 224ms/step - loss: 0.1197 - accuracy: 0.9532\n",
            "Epoch 50/100\n",
            "633/633 [==============================] - 143s 226ms/step - loss: 0.1168 - accuracy: 0.9559\n",
            "Epoch 51/100\n",
            "633/633 [==============================] - 144s 228ms/step - loss: 0.1156 - accuracy: 0.9544\n",
            "Epoch 52/100\n",
            "633/633 [==============================] - 146s 230ms/step - loss: 0.1142 - accuracy: 0.9568\n",
            "Epoch 53/100\n",
            "633/633 [==============================] - 146s 231ms/step - loss: 0.1095 - accuracy: 0.9576\n",
            "Epoch 54/100\n",
            "633/633 [==============================] - 145s 229ms/step - loss: 0.1109 - accuracy: 0.9575\n",
            "Epoch 55/100\n",
            "633/633 [==============================] - 146s 230ms/step - loss: 0.1065 - accuracy: 0.9592\n",
            "Epoch 56/100\n",
            "633/633 [==============================] - 146s 231ms/step - loss: 0.1082 - accuracy: 0.9581\n",
            "Epoch 57/100\n",
            "633/633 [==============================] - 147s 232ms/step - loss: 0.1062 - accuracy: 0.9595\n",
            "Epoch 58/100\n",
            "633/633 [==============================] - 146s 230ms/step - loss: 0.1039 - accuracy: 0.9595\n",
            "Epoch 59/100\n",
            "633/633 [==============================] - 146s 230ms/step - loss: 0.1018 - accuracy: 0.9611\n",
            "Epoch 60/100\n",
            "633/633 [==============================] - 147s 232ms/step - loss: 0.1008 - accuracy: 0.9616\n",
            "Epoch 61/100\n",
            "633/633 [==============================] - 146s 231ms/step - loss: 0.0994 - accuracy: 0.9613\n",
            "Epoch 62/100\n",
            "633/633 [==============================] - 146s 231ms/step - loss: 0.0967 - accuracy: 0.9638\n",
            "Epoch 63/100\n",
            "633/633 [==============================] - 146s 231ms/step - loss: 0.0974 - accuracy: 0.9635\n",
            "Epoch 64/100\n",
            "633/633 [==============================] - 147s 232ms/step - loss: 0.0948 - accuracy: 0.9636\n",
            "Epoch 65/100\n",
            "633/633 [==============================] - 146s 231ms/step - loss: 0.0934 - accuracy: 0.9648\n",
            "Epoch 66/100\n",
            "633/633 [==============================] - 146s 230ms/step - loss: 0.0926 - accuracy: 0.9643\n",
            "Epoch 67/100\n",
            "633/633 [==============================] - 146s 231ms/step - loss: 0.0914 - accuracy: 0.9650\n",
            "Epoch 68/100\n",
            "633/633 [==============================] - 146s 231ms/step - loss: 0.0886 - accuracy: 0.9663\n",
            "Epoch 69/100\n",
            "633/633 [==============================] - 153s 242ms/step - loss: 0.0864 - accuracy: 0.9673\n",
            "Epoch 70/100\n",
            "633/633 [==============================] - 151s 239ms/step - loss: 0.0860 - accuracy: 0.9669\n",
            "Epoch 71/100\n",
            "633/633 [==============================] - 151s 239ms/step - loss: 0.0847 - accuracy: 0.9683\n",
            "Epoch 72/100\n",
            "633/633 [==============================] - 149s 235ms/step - loss: 0.0848 - accuracy: 0.9679\n",
            "Epoch 73/100\n",
            "633/633 [==============================] - 148s 234ms/step - loss: 0.0841 - accuracy: 0.9679\n",
            "Epoch 74/100\n",
            "633/633 [==============================] - 147s 232ms/step - loss: 0.0826 - accuracy: 0.9683\n",
            "Epoch 75/100\n",
            "633/633 [==============================] - 147s 233ms/step - loss: 0.0812 - accuracy: 0.9689\n",
            "Epoch 76/100\n",
            "633/633 [==============================] - 148s 234ms/step - loss: 0.0791 - accuracy: 0.9702\n",
            "Epoch 77/100\n",
            "633/633 [==============================] - 148s 235ms/step - loss: 0.0786 - accuracy: 0.9707\n",
            "Epoch 78/100\n",
            "633/633 [==============================] - 148s 234ms/step - loss: 0.0775 - accuracy: 0.9712\n",
            "Epoch 79/100\n",
            "633/633 [==============================] - 149s 235ms/step - loss: 0.0758 - accuracy: 0.9715\n",
            "Epoch 80/100\n",
            "633/633 [==============================] - 149s 236ms/step - loss: 0.0757 - accuracy: 0.9721\n",
            "Epoch 81/100\n",
            "633/633 [==============================] - 149s 235ms/step - loss: 0.0772 - accuracy: 0.9714\n",
            "Epoch 82/100\n",
            "633/633 [==============================] - 150s 237ms/step - loss: 0.0751 - accuracy: 0.9716\n",
            "Epoch 83/100\n",
            "633/633 [==============================] - 152s 240ms/step - loss: 0.0741 - accuracy: 0.9726\n",
            "Epoch 84/100\n",
            "633/633 [==============================] - 150s 238ms/step - loss: 0.0729 - accuracy: 0.9733\n",
            "Epoch 85/100\n",
            "633/633 [==============================] - 154s 243ms/step - loss: 0.0731 - accuracy: 0.9725\n",
            "Epoch 86/100\n",
            "633/633 [==============================] - 159s 252ms/step - loss: 0.0717 - accuracy: 0.9732\n",
            "Epoch 87/100\n",
            "633/633 [==============================] - 152s 241ms/step - loss: 0.0689 - accuracy: 0.9748\n",
            "Epoch 88/100\n",
            "633/633 [==============================] - 151s 239ms/step - loss: 0.0692 - accuracy: 0.9741\n",
            "Epoch 89/100\n",
            "633/633 [==============================] - 154s 244ms/step - loss: 0.0674 - accuracy: 0.9751\n",
            "Epoch 90/100\n",
            "633/633 [==============================] - 154s 243ms/step - loss: 0.0679 - accuracy: 0.9754\n",
            "Epoch 91/100\n",
            "633/633 [==============================] - 152s 240ms/step - loss: 0.0674 - accuracy: 0.9746\n",
            "Epoch 92/100\n",
            "633/633 [==============================] - 151s 239ms/step - loss: 0.0674 - accuracy: 0.9753\n",
            "Epoch 93/100\n",
            "633/633 [==============================] - 152s 239ms/step - loss: 0.0657 - accuracy: 0.9756\n",
            "Epoch 94/100\n",
            "633/633 [==============================] - 151s 238ms/step - loss: 0.0659 - accuracy: 0.9753\n",
            "Epoch 95/100\n",
            "633/633 [==============================] - 152s 240ms/step - loss: 0.0632 - accuracy: 0.9769\n",
            "Epoch 96/100\n",
            "633/633 [==============================] - 150s 238ms/step - loss: 0.0631 - accuracy: 0.9764\n",
            "Epoch 97/100\n",
            "633/633 [==============================] - 150s 238ms/step - loss: 0.0619 - accuracy: 0.9773\n",
            "Epoch 98/100\n",
            "633/633 [==============================] - 150s 237ms/step - loss: 0.0625 - accuracy: 0.9768\n",
            "Epoch 99/100\n",
            "633/633 [==============================] - 150s 238ms/step - loss: 0.0612 - accuracy: 0.9778\n",
            "Epoch 100/100\n",
            "633/633 [==============================] - 150s 236ms/step - loss: 0.0610 - accuracy: 0.9780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xToowkfEKSeV"
      },
      "source": [
        "#save the model\n",
        "model.save_weights(path+'\\ddi2013-type\\\\DDI_w_studio_3.h5')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouXacnu3rxOj"
      },
      "source": [
        "#load only the w of the model, the model must be already executed\n",
        "model.load_weights(path+'\\ddi2013-type\\\\DDI_w_studio_3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MewUJ5gCPEmC"
      },
      "source": [
        "EVALUATE ALL DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nWACJzvHyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ebdd65-b500-4beb-949d-e4a2a8d19343"
      },
      "source": [
        "result_base=model.evaluate(embedded_trainset, five_hot_train, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET ORIGINARIO{result_base}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "633/633 [==============================] - 43s 68ms/step - loss: 0.0288 - accuracy: 0.9906\n",
            "DATASET ORIGINARIO[0.028838587924838066, 0.9906455874443054]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTieKJ_5UpKo",
        "outputId": "1c078d72-6d79-4f0f-b442-9ac9b5ec2fe8"
      },
      "source": [
        "result_base=model.evaluate(embedded_testset, five_hot_test, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET TEST{result_base}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195/195 [==============================] - 12s 59ms/step - loss: 0.9017 - accuracy: 0.8169\n",
            "DATASET TEST[0.9017105102539062, 0.8168720602989197]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjcdAwqeOi7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ae5487-37f5-4226-f722-e519d5541301"
      },
      "source": [
        "result_base=model.evaluate(embedded_origin, five_hot_orig, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET TEST{result_base}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 4s 58ms/step - loss: 0.8376 - accuracy: 0.8228\n",
            "DATASET TEST[0.8375811576843262, 0.822773814201355]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuaVK__WOjDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a812fbe6-81c4-4e16-c304-c16bb44e12b3"
      },
      "source": [
        "result_base=model.evaluate(embedded_sin, five_hot_sin, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET SINONIMI{result_base}')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 4s 59ms/step - loss: 0.9645 - accuracy: 0.8136\n",
            "DATASET SINONIMI[0.9645338654518127, 0.8135740160942078]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JgLKE2bOjLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029db369-3f67-4a14-c685-a52157afcb07"
      },
      "source": [
        "result_base=model.evaluate(embedded_emb, five_hot_emb, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET EMBEDDING{result_base}')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 4s 59ms/step - loss: 0.9030 - accuracy: 0.8143\n",
            "DATASET EMBEDDING[0.9030170440673828, 0.8142683506011963]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYacQtzVOMBX"
      },
      "source": [
        "tali test sono stati effettuati su windows, eventuali path necessitano di essere adattati, se effettuati su sistema operativo unix like.\n",
        "\n"
      ]
    }
  ]
}