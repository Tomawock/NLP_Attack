{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tomawock/NLP_Attack/blob/main/models/studio_3/DDI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiMkeY5Y_NZv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQcpBBopuQnf"
      },
      "source": [
        "!pip install optuna "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAgxUDSD-0pM"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow import keras\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvIuSdIzxK40"
      },
      "source": [
        "path=\"Desktop\\\\DDI\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Jt8EmX-IBe"
      },
      "source": [
        "path=\"/content/drive/Shareddrives/Deep Learning/datasets/DDI/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcgM45TxuiWB"
      },
      "source": [
        "PATH PER WINDOWDS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm8p2lwD_F5T"
      },
      "source": [
        "dev = pd.read_csv(path+'\\ddi2013-type\\\\dev.tsv', sep='\\t')\n",
        "test = pd.read_csv(path+'\\ddi2013-type\\\\test.tsv', sep='\\t')\n",
        "train = pd.read_csv(path+'\\ddi2013-type\\\\train.tsv', sep='\\t')\n",
        "\n",
        "data_sinonimi = pd.read_csv(path+\"\\ddi2013-type\\\\DDI_sinonimi_test.csv\")\n",
        "data_embedding = pd.read_csv(path+\"\\ddi2013-type\\\\DDI_embedding_test.csv\")\n",
        "\n",
        "data_embedding_train = pd.read_csv(path+\"\\ddi2013-type\\\\DDI_embedding.csv\")\n",
        "data_sinonimi_train = pd.read_csv(path+\"\\ddi2013-type\\\\DDI_sinonimi.csv\")\n",
        "\n",
        "print(test.shape)\n",
        "print(data_sinonimi.shape)\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw74BJhOugRM"
      },
      "source": [
        "dev = pd.read_csv(path+'ddi2013-type/dev.tsv', sep='\\t')\n",
        "test = pd.read_csv(path+'ddi2013-type/test.tsv', sep='\\t')\n",
        "train = pd.read_csv(path+'ddi2013-type/train.tsv', sep='\\t')\n",
        "\n",
        "data_sinonimi = pd.read_csv(path+\"ddi2013-type/DDI_sinonimi_test.csv\")\n",
        "data_embedding = pd.read_csv(path+\"ddi2013-type/DDI_embedding_test.csv\")\n",
        "\n",
        "data_embedding_train = pd.read_csv(path+\"ddi2013-type/DDI_embedding.csv\")\n",
        "\n",
        "print(test.shape)\n",
        "print(data_sinonimi.shape)\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YODJXjNIDjOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af84e85-a7d5-46a5-d0f0-fe910dcb95ee"
      },
      "source": [
        "test_study_1 = pd.concat([data_sinonimi, data_embedding], ignore_index=True)\n",
        "train_study_1 = pd.concat([data_sinonimi_train, data_embedding_train], ignore_index=True)\n",
        "print (test_study_1.shape)\n",
        "print (train_study_1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11522, 3)\n",
            "(37558, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdpEzJH3AAwb"
      },
      "source": [
        "print(train.shape)\n",
        "print(data_sinonimi.shape)\n",
        "print(data_embedding.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxqcDbYlANrk"
      },
      "source": [
        "print(train.label.value_counts())\n",
        "print(data_sinonimi.label.value_counts())\n",
        "print(data_embedding.label.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx5Dywe8E8gx"
      },
      "source": [
        "with open(path+\"\\word2index.pkl\", 'rb') as output:\n",
        "  w2i = pickle.load(output)\n",
        "with open(path+\"\\embedding_matrix.pkl\", 'rb') as output:\n",
        "  embedding_matrix = pickle.load(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv-nI15mvf4N"
      },
      "source": [
        "Set up per allenamento Modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUcRaXI_5f5i"
      },
      "source": [
        "categories = [['DDI-false', 'DDI-mechanism', 'DDI-effect', 'DDI-advise','DDI-int']]\n",
        "\n",
        "my_text_to_word_sequence = lambda sen: keras.preprocessing.text.text_to_word_sequence(sen,\n",
        "                                                                                      filters='!\"#&()*+,-./:;<=>?[\\\\]^_`\\'{|}~\\t\\n',\n",
        "                                                                                      lower=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ_NP5DJ5iDf"
      },
      "source": [
        "TRAINSET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AQtVajZE_Nv"
      },
      "source": [
        "five_hot_train = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  train_study_1.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ7yUd9tFEV6"
      },
      "source": [
        "sentences_train = [my_text_to_word_sequence(sentence) for sentence in train_study_1['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpyi_R0QM9yO"
      },
      "source": [
        "TESTSET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_bOaNrp5-9b"
      },
      "source": [
        "five_hot_test = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  test_study_1.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtLEyoQX6BME"
      },
      "source": [
        "sentences_test = [my_text_to_word_sequence(sentence) for sentence in test_study_1['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ylB78veIsv_"
      },
      "source": [
        "ORIGINALE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nViSudaIqQl"
      },
      "source": [
        "five_hot_orig = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  test.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znIsuAiwIyqd"
      },
      "source": [
        "sentences_orig = [my_text_to_word_sequence(sentence) for sentence in test['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP9Ku4JjM_4D"
      },
      "source": [
        "SINONIMI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F46YcI6F6DEP"
      },
      "source": [
        "five_hot_sin = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  data_sinonimi.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPjA_DfR6DWX"
      },
      "source": [
        "sentences_sin = [my_text_to_word_sequence(sentence) for sentence in data_sinonimi['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw5TZ84dNdNs"
      },
      "source": [
        "EMBEDDING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwCdjTJ-6K6x"
      },
      "source": [
        "five_hot_emb = OneHotEncoder(sparse=False, categories=categories).fit_transform(\n",
        "  data_embedding.label.to_numpy().reshape(-1, 1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOzh1rcV6LEl"
      },
      "source": [
        "sentences_emb = [my_text_to_word_sequence(sentence) for sentence in data_embedding['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBbI74mh5Vs_"
      },
      "source": [
        "Estrai la massima dimensione dell'input in base ai vari dataset considerati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP3eoSK35U8J"
      },
      "source": [
        "max_index, max = (-1, -1)\n",
        "for i, sentence in enumerate(sentences_train):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_orig):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "  \n",
        "print(f'Il massimo è {max}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEM1DpJEGtd"
      },
      "source": [
        "Crao i vari embedding per tutti i dataset, quest'operazione e pesante "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU4vzy2XFMNw"
      },
      "source": [
        "embedded_trainset = np.zeros(shape=(len(sentences_train), max, 300))\n",
        "for i, sentence in enumerate(sentences_train):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_trainset[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcTLLtVaT_3x"
      },
      "source": [
        "embedded_origin = np.zeros(shape=(len(sentences_orig), max, 300))\n",
        "for i, sentence in enumerate(sentences_orig):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_origin[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzIOhX8XMGS8"
      },
      "source": [
        "embedded_testset = np.zeros(shape=(len(sentences_test), max, 300))\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_testset[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-G-eEVMM_gB"
      },
      "source": [
        "embedded_sin = np.zeros(shape=(len(sentences_sin), max, 300))\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_sin[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR8cp_siNfYB"
      },
      "source": [
        "embedded_emb = np.zeros(shape=(len(sentences_emb), max, 300))\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_emb[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG87uMvKvm0L"
      },
      "source": [
        "Carica optuna results e inizializza il modello, oppure salva il modello oppure carica solo i pesi del modello "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b16mA7IuBRrK"
      },
      "source": [
        "best_params = optuna.load_study(study_name=\"DDI\", storage=\"sqlite:///\"+path+\"\\ddi2013-type\\\\optuna_ddi_studio_0.db\").best_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMwRMnYDCMSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff902a50-18a6-47d3-fbda-5feb54eab84d"
      },
      "source": [
        "print(f'{best_params}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 89, 'dropout': 0.63, 'units': 81}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVMfBNRxCuy6"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Input(shape=(max, 300)))\n",
        "model.add(keras.layers.Bidirectional(layer=keras.layers.LSTM(units=best_params['units'],\n",
        "                                                             recurrent_dropout=best_params['dropout'],\n",
        "                                                             activation='tanh')))\n",
        "\n",
        "model.add(keras.layers.Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxDADamsukZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d78074-a41b-42c4-e30c-18685b15696b"
      },
      "source": [
        "#train the model\n",
        "result = model.fit(embedded_trainset,\n",
        "                   five_hot_train,\n",
        "                   epochs=100,\n",
        "                   batch_size=best_params['batch_size'],\n",
        "                   callbacks=[keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                            patience=10)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "422/422 [==============================] - 96s 227ms/step - loss: 0.5879 - accuracy: 0.8417\n",
            "Epoch 2/100\n",
            "422/422 [==============================] - 98s 232ms/step - loss: 0.4845 - accuracy: 0.8451\n",
            "Epoch 3/100\n",
            "422/422 [==============================] - 96s 227ms/step - loss: 0.4403 - accuracy: 0.8472\n",
            "Epoch 4/100\n",
            "422/422 [==============================] - 90s 213ms/step - loss: 0.4146 - accuracy: 0.8492\n",
            "Epoch 5/100\n",
            "422/422 [==============================] - 90s 214ms/step - loss: 0.3934 - accuracy: 0.8528\n",
            "Epoch 6/100\n",
            "422/422 [==============================] - 92s 219ms/step - loss: 0.3795 - accuracy: 0.8535\n",
            "Epoch 7/100\n",
            "422/422 [==============================] - 92s 218ms/step - loss: 0.3655 - accuracy: 0.8567\n",
            "Epoch 8/100\n",
            "422/422 [==============================] - 91s 215ms/step - loss: 0.3533 - accuracy: 0.8601\n",
            "Epoch 9/100\n",
            "422/422 [==============================] - 91s 215ms/step - loss: 0.3441 - accuracy: 0.8624\n",
            "Epoch 10/100\n",
            "422/422 [==============================] - 91s 215ms/step - loss: 0.3314 - accuracy: 0.8659\n",
            "Epoch 11/100\n",
            "422/422 [==============================] - 93s 220ms/step - loss: 0.3205 - accuracy: 0.8699\n",
            "Epoch 12/100\n",
            "422/422 [==============================] - 92s 219ms/step - loss: 0.3089 - accuracy: 0.8743\n",
            "Epoch 13/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.3007 - accuracy: 0.8773\n",
            "Epoch 14/100\n",
            "422/422 [==============================] - 90s 214ms/step - loss: 0.2944 - accuracy: 0.8811\n",
            "Epoch 15/100\n",
            "422/422 [==============================] - 90s 214ms/step - loss: 0.2851 - accuracy: 0.8838\n",
            "Epoch 16/100\n",
            "422/422 [==============================] - 91s 215ms/step - loss: 0.2774 - accuracy: 0.8851\n",
            "Epoch 17/100\n",
            "422/422 [==============================] - 89s 211ms/step - loss: 0.2695 - accuracy: 0.8904\n",
            "Epoch 18/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.2626 - accuracy: 0.8924\n",
            "Epoch 19/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.2564 - accuracy: 0.8947\n",
            "Epoch 20/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.2531 - accuracy: 0.8981\n",
            "Epoch 21/100\n",
            "422/422 [==============================] - 91s 214ms/step - loss: 0.2453 - accuracy: 0.8987\n",
            "Epoch 22/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.2404 - accuracy: 0.9016\n",
            "Epoch 23/100\n",
            "422/422 [==============================] - 92s 217ms/step - loss: 0.2354 - accuracy: 0.9047\n",
            "Epoch 24/100\n",
            "422/422 [==============================] - 91s 215ms/step - loss: 0.2292 - accuracy: 0.9065\n",
            "Epoch 25/100\n",
            "422/422 [==============================] - 90s 214ms/step - loss: 0.2233 - accuracy: 0.9080\n",
            "Epoch 26/100\n",
            "422/422 [==============================] - 90s 214ms/step - loss: 0.2220 - accuracy: 0.9105\n",
            "Epoch 27/100\n",
            "422/422 [==============================] - 92s 217ms/step - loss: 0.2150 - accuracy: 0.9132\n",
            "Epoch 28/100\n",
            "422/422 [==============================] - 93s 221ms/step - loss: 0.2129 - accuracy: 0.9134\n",
            "Epoch 29/100\n",
            "422/422 [==============================] - 97s 231ms/step - loss: 0.2072 - accuracy: 0.9153\n",
            "Epoch 30/100\n",
            "422/422 [==============================] - 99s 234ms/step - loss: 0.2026 - accuracy: 0.9178\n",
            "Epoch 31/100\n",
            "422/422 [==============================] - 97s 230ms/step - loss: 0.1977 - accuracy: 0.9209\n",
            "Epoch 32/100\n",
            "422/422 [==============================] - 97s 230ms/step - loss: 0.1936 - accuracy: 0.9215\n",
            "Epoch 33/100\n",
            "422/422 [==============================] - 98s 232ms/step - loss: 0.1907 - accuracy: 0.9241\n",
            "Epoch 34/100\n",
            "422/422 [==============================] - 100s 237ms/step - loss: 0.1867 - accuracy: 0.9251\n",
            "Epoch 35/100\n",
            "422/422 [==============================] - 103s 245ms/step - loss: 0.1849 - accuracy: 0.9253\n",
            "Epoch 36/100\n",
            "422/422 [==============================] - 101s 239ms/step - loss: 0.1814 - accuracy: 0.9276\n",
            "Epoch 37/100\n",
            "422/422 [==============================] - 102s 241ms/step - loss: 0.1789 - accuracy: 0.9289\n",
            "Epoch 38/100\n",
            "422/422 [==============================] - 103s 243ms/step - loss: 0.1731 - accuracy: 0.9315\n",
            "Epoch 39/100\n",
            "422/422 [==============================] - 101s 239ms/step - loss: 0.1714 - accuracy: 0.9323\n",
            "Epoch 40/100\n",
            "422/422 [==============================] - 101s 239ms/step - loss: 0.1687 - accuracy: 0.9324\n",
            "Epoch 41/100\n",
            "422/422 [==============================] - 101s 240ms/step - loss: 0.1664 - accuracy: 0.9337\n",
            "Epoch 42/100\n",
            "422/422 [==============================] - 102s 241ms/step - loss: 0.1619 - accuracy: 0.9360\n",
            "Epoch 43/100\n",
            "422/422 [==============================] - 106s 250ms/step - loss: 0.1610 - accuracy: 0.9370\n",
            "Epoch 44/100\n",
            "422/422 [==============================] - 103s 245ms/step - loss: 0.1583 - accuracy: 0.9377\n",
            "Epoch 45/100\n",
            "422/422 [==============================] - 102s 242ms/step - loss: 0.1544 - accuracy: 0.9393\n",
            "Epoch 46/100\n",
            "422/422 [==============================] - 98s 231ms/step - loss: 0.1543 - accuracy: 0.9400\n",
            "Epoch 47/100\n",
            "422/422 [==============================] - 98s 231ms/step - loss: 0.1487 - accuracy: 0.9424\n",
            "Epoch 48/100\n",
            "422/422 [==============================] - 98s 233ms/step - loss: 0.1480 - accuracy: 0.9424\n",
            "Epoch 49/100\n",
            "422/422 [==============================] - 99s 234ms/step - loss: 0.1446 - accuracy: 0.9437\n",
            "Epoch 50/100\n",
            "422/422 [==============================] - 97s 230ms/step - loss: 0.1441 - accuracy: 0.9429\n",
            "Epoch 51/100\n",
            "422/422 [==============================] - 95s 224ms/step - loss: 0.1411 - accuracy: 0.9452\n",
            "Epoch 52/100\n",
            "422/422 [==============================] - 96s 227ms/step - loss: 0.1381 - accuracy: 0.9457\n",
            "Epoch 53/100\n",
            "422/422 [==============================] - 97s 230ms/step - loss: 0.1354 - accuracy: 0.9475\n",
            "Epoch 54/100\n",
            "422/422 [==============================] - 95s 226ms/step - loss: 0.1330 - accuracy: 0.9496\n",
            "Epoch 55/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.1320 - accuracy: 0.9483\n",
            "Epoch 56/100\n",
            "422/422 [==============================] - 91s 215ms/step - loss: 0.1318 - accuracy: 0.9486\n",
            "Epoch 57/100\n",
            "422/422 [==============================] - 92s 218ms/step - loss: 0.1265 - accuracy: 0.9509\n",
            "Epoch 58/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.1263 - accuracy: 0.9507\n",
            "Epoch 59/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.1259 - accuracy: 0.9508\n",
            "Epoch 60/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.1219 - accuracy: 0.9534\n",
            "Epoch 61/100\n",
            "422/422 [==============================] - 92s 218ms/step - loss: 0.1223 - accuracy: 0.9525\n",
            "Epoch 62/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.1204 - accuracy: 0.9534\n",
            "Epoch 63/100\n",
            "422/422 [==============================] - 91s 216ms/step - loss: 0.1170 - accuracy: 0.9543\n",
            "Epoch 64/100\n",
            "422/422 [==============================] - 92s 219ms/step - loss: 0.1161 - accuracy: 0.9556\n",
            "Epoch 65/100\n",
            "422/422 [==============================] - 92s 218ms/step - loss: 0.1134 - accuracy: 0.9572\n",
            "Epoch 66/100\n",
            "422/422 [==============================] - 92s 217ms/step - loss: 0.1135 - accuracy: 0.9554\n",
            "Epoch 67/100\n",
            "422/422 [==============================] - 91s 217ms/step - loss: 0.1098 - accuracy: 0.9584\n",
            "Epoch 68/100\n",
            "422/422 [==============================] - 92s 218ms/step - loss: 0.1106 - accuracy: 0.9575\n",
            "Epoch 69/100\n",
            "422/422 [==============================] - 100s 236ms/step - loss: 0.1070 - accuracy: 0.9591\n",
            "Epoch 70/100\n",
            "422/422 [==============================] - 99s 235ms/step - loss: 0.1060 - accuracy: 0.9589\n",
            "Epoch 71/100\n",
            "422/422 [==============================] - 98s 233ms/step - loss: 0.1094 - accuracy: 0.9581\n",
            "Epoch 72/100\n",
            "422/422 [==============================] - 97s 230ms/step - loss: 0.1042 - accuracy: 0.9612\n",
            "Epoch 73/100\n",
            "422/422 [==============================] - 99s 234ms/step - loss: 0.1034 - accuracy: 0.9611\n",
            "Epoch 74/100\n",
            "422/422 [==============================] - 99s 234ms/step - loss: 0.0986 - accuracy: 0.9625\n",
            "Epoch 75/100\n",
            "422/422 [==============================] - 96s 227ms/step - loss: 0.1002 - accuracy: 0.9625\n",
            "Epoch 76/100\n",
            "422/422 [==============================] - 99s 234ms/step - loss: 0.0998 - accuracy: 0.9620\n",
            "Epoch 77/100\n",
            "422/422 [==============================] - 95s 225ms/step - loss: 0.0982 - accuracy: 0.9629\n",
            "Epoch 78/100\n",
            "422/422 [==============================] - 98s 232ms/step - loss: 0.0941 - accuracy: 0.9642\n",
            "Epoch 79/100\n",
            "422/422 [==============================] - 97s 231ms/step - loss: 0.0945 - accuracy: 0.9626\n",
            "Epoch 80/100\n",
            "422/422 [==============================] - 99s 234ms/step - loss: 0.0933 - accuracy: 0.9645\n",
            "Epoch 81/100\n",
            "422/422 [==============================] - 99s 235ms/step - loss: 0.0914 - accuracy: 0.9661\n",
            "Epoch 82/100\n",
            "422/422 [==============================] - 99s 235ms/step - loss: 0.0934 - accuracy: 0.9646\n",
            "Epoch 83/100\n",
            "422/422 [==============================] - 94s 223ms/step - loss: 0.0903 - accuracy: 0.9663\n",
            "Epoch 84/100\n",
            "422/422 [==============================] - 95s 224ms/step - loss: 0.0897 - accuracy: 0.9672\n",
            "Epoch 85/100\n",
            "422/422 [==============================] - 97s 229ms/step - loss: 0.0877 - accuracy: 0.9666\n",
            "Epoch 86/100\n",
            "422/422 [==============================] - 95s 225ms/step - loss: 0.0885 - accuracy: 0.9666\n",
            "Epoch 87/100\n",
            "422/422 [==============================] - 95s 226ms/step - loss: 0.0865 - accuracy: 0.9678\n",
            "Epoch 88/100\n",
            "422/422 [==============================] - 97s 230ms/step - loss: 0.0848 - accuracy: 0.9677\n",
            "Epoch 89/100\n",
            "422/422 [==============================] - 101s 240ms/step - loss: 0.0842 - accuracy: 0.9684\n",
            "Epoch 90/100\n",
            "422/422 [==============================] - 104s 247ms/step - loss: 0.0829 - accuracy: 0.9694\n",
            "Epoch 91/100\n",
            "422/422 [==============================] - 105s 248ms/step - loss: 0.0831 - accuracy: 0.9693\n",
            "Epoch 92/100\n",
            "422/422 [==============================] - 104s 247ms/step - loss: 0.0799 - accuracy: 0.9694\n",
            "Epoch 93/100\n",
            "422/422 [==============================] - 104s 247ms/step - loss: 0.0786 - accuracy: 0.9710\n",
            "Epoch 94/100\n",
            "422/422 [==============================] - 104s 247ms/step - loss: 0.0798 - accuracy: 0.9702\n",
            "Epoch 95/100\n",
            "422/422 [==============================] - 103s 244ms/step - loss: 0.0781 - accuracy: 0.9702\n",
            "Epoch 96/100\n",
            "422/422 [==============================] - 104s 247ms/step - loss: 0.0752 - accuracy: 0.9721\n",
            "Epoch 97/100\n",
            "422/422 [==============================] - 105s 249ms/step - loss: 0.0768 - accuracy: 0.9706\n",
            "Epoch 98/100\n",
            "422/422 [==============================] - 105s 248ms/step - loss: 0.0754 - accuracy: 0.9720\n",
            "Epoch 99/100\n",
            "422/422 [==============================] - 105s 248ms/step - loss: 0.0735 - accuracy: 0.9727\n",
            "Epoch 100/100\n",
            "422/422 [==============================] - 106s 251ms/step - loss: 0.0734 - accuracy: 0.9728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xToowkfEKSeV"
      },
      "source": [
        "#save the model\n",
        "model.save_weights(path+'\\ddi2013-type\\\\DDI_w_studio_3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouXacnu3rxOj"
      },
      "source": [
        "#load only the w of the model, the model must be already executed\n",
        "model.load_weights(path+'\\ddi2013-type\\\\DDI_w_studio_3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MewUJ5gCPEmC"
      },
      "source": [
        "EVALUATE ALL DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nWACJzvHyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e742bc00-c9fc-486c-8dd1-600fcd16604d"
      },
      "source": [
        "result_base=model.evaluate(embedded_trainset, five_hot_train, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET ORIGINARIO{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 28s 65ms/step - loss: 0.0363 - accuracy: 0.9896\n",
            "DATASET ORIGINARIO[0.036323703825473785, 0.9895894527435303]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTieKJ_5UpKo",
        "outputId": "85f6d34d-b246-4d19-edd1-eddb2932c6b9"
      },
      "source": [
        "result_base=model.evaluate(embedded_testset, five_hot_test, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET TEST{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130/130 [==============================] - 8s 63ms/step - loss: 0.9850 - accuracy: 0.8177\n",
            "DATASET TEST[0.9849727749824524, 0.8177399635314941]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjcdAwqeOi7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8097d5-b1db-4540-fff1-015c58c805a6"
      },
      "source": [
        "result_base=model.evaluate(embedded_origin, five_hot_orig, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET TEST{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 4s 63ms/step - loss: 0.8900 - accuracy: 0.7934\n",
            "DATASET TEST[0.8900015354156494, 0.7934386134147644]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuaVK__WOjDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9be759-9df2-4ae3-acd7-d7ddb55c2db3"
      },
      "source": [
        "result_base=model.evaluate(embedded_sin, five_hot_sin, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET SINONIMI{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 4s 62ms/step - loss: 1.0264 - accuracy: 0.8165\n",
            "DATASET SINONIMI[1.0263546705245972, 0.8165249228477478]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JgLKE2bOjLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed564892-eb8f-4bf7-d8ff-7d9df299a5a5"
      },
      "source": [
        "result_base=model.evaluate(embedded_emb, five_hot_emb, batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET EMBEDDING{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65/65 [==============================] - 4s 66ms/step - loss: 0.9436 - accuracy: 0.8190\n",
            "DATASET EMBEDDING[0.9435904026031494, 0.8189550638198853]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYacQtzVOMBX"
      },
      "source": [
        "tali test sono stati effettuati su windows, eventuali path necessitano di essere adattati, se effettuati su sistema operativo unix like.\n",
        "\n"
      ]
    }
  ]
}