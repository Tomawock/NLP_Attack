{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tomawock/NLP_Attack/blob/main/models/studio_0/ate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-DWn9G8qo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f171f7-2e48-41e6-c427-c018cdb97046"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhZgkl4B_XVu"
      },
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvIOj4268c1y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9omR98sh9v-r"
      },
      "source": [
        "path=\"/content/drive/Shareddrives/Deep Learning/datasets/ATE_ABSITA/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPJoY-GO8suc"
      },
      "source": [
        "test = pd.read_json(path+'ATE_ABSITA_test_set/ate_absita_gold.ndjson',\n",
        "                    lines=True)\n",
        "\n",
        "train = pd.read_json(path+'ATE_ABSITA_training_set/ate_absita_training.ndjson',\n",
        "                     lines=True)\n",
        "\n",
        "data_sinonimi = pd.read_csv(path+\"ATE_ABSITA_test_set/sinonimi.csv\")\n",
        "data_embedding = pd.read_csv(path+\"ATE_ABSITA_test_set/embedding.csv\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1OCMqGV8szX"
      },
      "source": [
        "print(test.columns)\n",
        "print(train.columns)\n",
        "print(data_sinonimi.columns)\n",
        "print(data_embedding.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbAHXJR78s3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a623c149-7734-4a5b-a7da-cb59502511d5"
      },
      "source": [
        "train.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "test.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "data_sinonimi.drop(columns=['polarities','aspects_position','aspects'], inplace=True)\n",
        "data_embedding.drop(columns=['polarities','aspects_position','aspects'], inplace=True)\n",
        "print(f'Contains {len(train)} sentences')\n",
        "print(f'Contains {len(test)} sentences')\n",
        "print(f'Contains {len(data_sinonimi)} sentences')\n",
        "print(f'Contains {len(data_embedding)} sentences')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contains 3054 sentences\n",
            "Contains 1200 sentences\n",
            "Contains 1200 sentences\n",
            "Contains 1200 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iePD6n9p82nG"
      },
      "source": [
        "Creazione colonna Positivi/Negativi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuCtCXCw8s6M"
      },
      "source": [
        "train[\"review_type\"] = train[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "test[\"review_type\"] = test[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "data_sinonimi[\"review_type\"] = data_sinonimi[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "data_embedding[\"review_type\"] = data_embedding[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "\n",
        "print(f'TRAIN::\\n{train.review_type.value_counts()}')\n",
        "print(f'TEST::\\n{test.review_type.value_counts()}')\n",
        "print(f'SINONIMI::\\n{data_sinonimi.review_type.value_counts()}')\n",
        "print(f'EMBEDDING::\\n{data_embedding.review_type.value_counts()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru-WHUt788NG"
      },
      "source": [
        "Rimozione Colonna Score in quanto non piu significativa per la Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqPpoik2AJJZ"
      },
      "source": [
        "train.drop(columns=['score'], inplace=True)\n",
        "test.drop(columns=['score'], inplace=True)\n",
        "data_sinonimi.drop(columns=['score'], inplace=True)\n",
        "data_embedding.drop(columns=['score'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTQldsfF8s8_"
      },
      "source": [
        "with open(path+\"word2index.pkl\", 'rb') as output:\n",
        "  w2i = pickle.load(output)\n",
        "with open(path+\"embedding_matrix.pkl\", 'rb') as output:\n",
        "  embedding_matrix = pickle.load(output)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21BASbk79EIe"
      },
      "source": [
        "Trasformazione input da frasi a vettori di parole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv5nfe958s_s"
      },
      "source": [
        "def my_text_to_word_sequence(sentence):\n",
        "  return keras.preprocessing.text.text_to_word_sequence(sentence,\n",
        "                                                        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`\\'{|}~\\t\\n',\n",
        "                                                        lower=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHcjEZ6j9g_F"
      },
      "source": [
        "TRAIN, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lPd3qFfAqJl"
      },
      "source": [
        "one_hot_train = OneHotEncoder(sparse=False).fit_transform(\n",
        "        train.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_bOaNrp5-9b"
      },
      "source": [
        "sentences = [my_text_to_word_sequence(sentence) for sentence in train['sentence']]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzm3YxooRiWW"
      },
      "source": [
        "TEST, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqK9OLeoRiWY"
      },
      "source": [
        "one_hot_test = OneHotEncoder(sparse=False).fit_transform(\n",
        "        test.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvsh3KbXRiWY"
      },
      "source": [
        "sentences_test = [my_text_to_word_sequence(sentence) for sentence in test['sentence']]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtqBuF4zRi--"
      },
      "source": [
        "SINONIMI, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0sNiYBERi_A"
      },
      "source": [
        "one_hot_sin = OneHotEncoder(sparse=False).fit_transform(\n",
        "        data_sinonimi.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwa-A7qfRi_B"
      },
      "source": [
        "sentences_sin = [my_text_to_word_sequence(sentence) for sentence in data_sinonimi['sentence']]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrUKHOU9RjeZ"
      },
      "source": [
        "EMBEDDING, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l8HELWMRjea"
      },
      "source": [
        "one_hot_emb = OneHotEncoder(sparse=False).fit_transform(\n",
        "        data_embedding.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pA2ra7HRjeb"
      },
      "source": [
        "sentences_emb = [my_text_to_word_sequence(sentence) for sentence in data_embedding['sentence']]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeTE81j_9cOv"
      },
      "source": [
        "Estrai la massima dimensione dell'input in base ai vari dataset considerati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pudlFdxF8tCA",
        "outputId": "1758a10f-f1ae-4356-fdc6-8296d4501052"
      },
      "source": [
        "max_index, max = (-1, -1)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "\n",
        "\n",
        "print(f'Il massimo è {max}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il massimo è 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbKTvQuOEaP3"
      },
      "source": [
        "Crao i vari embedding per tutti i dataset, quest'operazione e pesante "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfA2XQzE9hdL"
      },
      "source": [
        "embedded_trainset = np.zeros(shape=(len(sentences), max, 300))\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_trainset[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZW78yxjTJly"
      },
      "source": [
        "embedded_test = np.zeros(shape=(len(sentences_test), max, 300))\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_testset[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkN3_ZGQTK49"
      },
      "source": [
        "embedded_sin = np.zeros(shape=(len(sentences_sin), max, 300))\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_sin[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcf1fth5TLGy"
      },
      "source": [
        "embedded_emb = np.zeros(shape=(len(sentences_emb), max, 300))\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_emb[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5rb4COz9oVn"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IHhcxg49qg5"
      },
      "source": [
        "best_params = optuna.load_study(study_name=\"ATE\", storage=\"sqlite:///\"+path+\"optuna_ATE_studio_0.db\").best_params"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM6k1Bf08TJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002d5ae8-0398-4800-d01b-d8a20184e5b1"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Input(shape=(max, 300)))\n",
        "model.add(keras.layers.Bidirectional(layer=keras.layers.LSTM(units=best_params[\"units\"],\n",
        "                                                             recurrent_dropout=best_params[\"dropout\"],\n",
        "                                                             activation='tanh')))\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=keras.optimizers.Adam(0.001),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8t68xO9BMmb"
      },
      "source": [
        "#train model\n",
        "result = model.fit(embedded_trainset,\n",
        "                 one_hot_train,\n",
        "                 epochs=100,\n",
        "                 batch_size=best_params[\"batch_size\"],\n",
        "                 callbacks=[keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                            patience=10)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbstjV0B9qmF"
      },
      "source": [
        "#save the model\n",
        "model.save_weights(path+'ATE_w_studio_0.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmdfbdbGBQMT"
      },
      "source": [
        "model.load_weights(path+'ATE_w_studio_0.h5')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Y6MEPfCRC-"
      },
      "source": [
        "#EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nWACJzvHyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebb0093-76d5-4cd1-dc47-cf10443a946d"
      },
      "source": [
        "result_base=model.evaluate(embedded_trainset,one_hot_train,batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET ORIGINARIO{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 6s 46ms/step - loss: 0.0164 - accuracy: 0.9969\n",
            "DATASET ORIGINARIO[0.01643429324030876, 0.9967256188392639]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjcdAwqeOi7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e07f0a4-53be-4ba6-fcaa-74d1beea39cb"
      },
      "source": [
        "result_base=model.evaluate(embedded_test,one_hot_test,batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET DEV{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 1s 47ms/step - loss: 0.6068 - accuracy: 0.7142\n",
            "DATASET DEV[0.6067888140678406, 0.7141666412353516]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuaVK__WOjDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8936ae-be59-43f7-84a7-a37203fcc600"
      },
      "source": [
        "result_base=model.evaluate(embedded_sin,one_hot_sin,batch_size=best_params['batch_size'])\n",
        "print(f'DATASET SINONIMI{result_base}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 1s 44ms/step - loss: 1.7832 - accuracy: 0.6433\n",
            "DATASET SINONIMI[1.7832045555114746, 0.6433333158493042]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JgLKE2bOjLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ece728-fb5c-457b-edb3-3111c6208801"
      },
      "source": [
        "result_base=model.evaluate(embedded_emb,one_hot_emb,batch_size=best_params['batch_size'])\n",
        "print(f'DATASET EMBEDDING{result_base}')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 1s 40ms/step - loss: 1.6284 - accuracy: 0.6650\n",
            "DATASET EMBEDDING[1.6283600330352783, 0.6650000214576721]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}