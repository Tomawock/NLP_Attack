{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amazon.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tomawock/NLP_Attack/blob/main/models/documented_model/amazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWKwPomViKdD",
        "outputId": "0191bd56-3692-40c4-e7a3-142a15827a47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow_text"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text) (0.11.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.3.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.32.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.12.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (51.3.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS86AJL_dcdy",
        "outputId": "7a13c99c-7eb6-447d-a636-c8232ac67425"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rkxWSNKdmgb"
      },
      "source": [
        "# nostri import \r\n",
        "import random\r\n",
        "import pickle\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import tensorflow_hub as hub\r\n",
        "import tensorflow_text #necessaria per hub.load"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2GoKWeXd6Cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eeea1f6-d68f-477b-f9ec-bf9a8f96eeb9"
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07yZmnQAp6E1"
      },
      "source": [
        "Pulizia del dataset da dei dati inutili per l'esperimento\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lprv3rB1dytR",
        "outputId": "0f025864-d441-4778-d918-7265e2ece07f"
      },
      "source": [
        "df = pd.read_csv('/content/drive/Shareddrives/Deep Learning/datasets/Amazon/Reviews.csv')\r\n",
        "print(f\"COLONNE:{df.columns}\")\r\n",
        "print(f\"DIMENSIONE:{df.shape}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COLONNE:Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
            "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
            "      dtype='object')\n",
            "DIMENSIONE:(568454, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFqpboIseHZo"
      },
      "source": [
        "del df['Id']\r\n",
        "del df['ProductId']\r\n",
        "del df['UserId']\r\n",
        "del df['ProfileName']\r\n",
        "del df['HelpfulnessNumerator']\r\n",
        "del df['HelpfulnessDenominator']\r\n",
        "del df['Time']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZytSm-UDqFwt"
      },
      "source": [
        "creazione colonna review data dall'unione del summary ed il testo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rR3QSVYCeIRH",
        "outputId": "9be25207-e6ba-4e43-faae-564863eb6878"
      },
      "source": [
        "df['review'] = df['Summary']+df['Text']\r\n",
        "del df['Summary']\r\n",
        "del df['Text']\r\n",
        "df.review.fillna(\"\",inplace = True)\r\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>Good Quality Dog FoodI have bought several of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Not as AdvertisedProduct arrived labeled as Ju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Delight\" says it allThis is a confection that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Cough MedicineIf you are looking for the secre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Great taffyGreat taffy at a great price.  Ther...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Score                                             review\n",
              "0      5  Good Quality Dog FoodI have bought several of ...\n",
              "1      1  Not as AdvertisedProduct arrived labeled as Ju...\n",
              "2      4  \"Delight\" says it allThis is a confection that...\n",
              "3      2  Cough MedicineIf you are looking for the secre...\n",
              "4      5  Great taffyGreat taffy at a great price.  Ther..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P21RJ-oIqTzB"
      },
      "source": [
        "Creazione review type al posto dello score, per avere tutte le frasi con valutazione minore di 4 come negative e le rimanneti come positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt8WX-qGeOTZ"
      },
      "source": [
        "df[\"review_type\"] = df[\"Score\"].apply(lambda x: \"negative\" if x < 4 else \"positive\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL006_FWrSwL"
      },
      "source": [
        "del df['Score']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddxTumAbeiYX",
        "outputId": "faa06481-eb51-4a57-a2ac-aacb3d15d592"
      },
      "source": [
        "df.review_type.value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    443777\n",
              "negative    124677\n",
              "Name: review_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlIGPu8OqoqX"
      },
      "source": [
        "Bilanciamento delle sentence positive con quelle negative, in modo da avere un dataset bilanciato, fatto 50 50 poiche si hanno a disposizione molti dati "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eacu1K9sew8b"
      },
      "source": [
        "positive_reviews = df[df.review_type == \"positive\"]\r\n",
        "negative_reviews = df[df.review_type == \"negative\"]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91KCyFZfSl2"
      },
      "source": [
        "RANDOM_SEED = 42\r\n",
        "np.random.seed(RANDOM_SEED)\r\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4hOsTGmeqfW"
      },
      "source": [
        "positive_df = positive_reviews.sample(n=len(negative_reviews), random_state=RANDOM_SEED)\r\n",
        "negative_df = negative_reviews"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJHE4EbNfZYl",
        "outputId": "3d8967cd-62ea-4b95-ca5a-5575d7b5565a"
      },
      "source": [
        "review_df = positive_df.append(negative_df).reset_index(drop=True)\r\n",
        "review_df.shape\r\n",
        "print(review_df.columns)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['review', 'review_type'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VFcnhJGWQ34"
      },
      "source": [
        "## **Modello unico**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtirymX9ruyP"
      },
      "source": [
        "Creazione one hot encoding per il review_type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqimzk_AWU6X"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "\r\n",
        "type_one_hot = OneHotEncoder(sparse=False).fit_transform(\r\n",
        "  review_df.review_type.to_numpy().reshape(-1, 1)\r\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOgTsbgYr9vx"
      },
      "source": [
        "Creazione test e train set per il modello, generato tramite **train_test_split**,  70/30 con seed identico a quello usato per il campionamemto dei dati per il bilancaiamento del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thqzi445WU6Y"
      },
      "source": [
        "train_reviews, test_reviews, y_train, y_test =\\\r\n",
        "  train_test_split(\r\n",
        "    review_df.review, \r\n",
        "    type_one_hot, \r\n",
        "    test_size=.3, \r\n",
        "    random_state=RANDOM_SEED\r\n",
        "  )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqxTeeQZi3DW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cac7a63-8b1b-416c-ca68-fdaa6e2d75ae"
      },
      "source": [
        "print(train_reviews.shape)\n",
        "print(test_reviews.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(174547,)\n",
            "(74807,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g12ZCzMhsk95"
      },
      "source": [
        "Caricamento dell'embedding e creazione della funzione usata dal modello per usarlo all'interno dello stesso e non come preprocessing del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV2ljtaAXfQK"
      },
      "source": [
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL53jJ_YIc_S",
        "outputId": "14f7b5d9-1cb4-4e1f-d0c0-45f858b5b748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Input(shape=(1,), dtype=tf.string))\n",
        "model.add(keras.layers.Lambda(lambda x: tf.squeeze(tf.cast(x, tf.string))))\n",
        "model.add(hub.KerasLayer(handle=embed,output_shape=512)) # pre trained Convolutional Neural Net. \n",
        "model.add(keras.layers.Dense(units=256, activation='relu')) \n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
        "model.add(keras.layers.Dropout(rate=0.2))\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_4 (Lambda)            None                      0         \n",
            "_________________________________________________________________\n",
            "keras_layer_6 (KerasLayer)   (None, 512)               85213184  \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 85,377,666\n",
            "Trainable params: 164,482\n",
            "Non-trainable params: 85,213,184\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYPOUQHcWnaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b949b0-b39e-4573-a4bc-6e34390209eb"
      },
      "source": [
        "history = model.fit(\n",
        "    train_reviews[:2500], y_train[:2500], \n",
        "    epochs=2, \n",
        "    batch_size=16, \n",
        "    validation_split=0.1, \n",
        "    verbose=1, \n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "141/141 [==============================] - 25s 143ms/step - loss: 0.5720 - accuracy: 0.6768 - val_loss: 0.3623 - val_accuracy: 0.8120\n",
            "Epoch 2/2\n",
            "141/141 [==============================] - 17s 122ms/step - loss: 0.3432 - accuracy: 0.8474 - val_loss: 0.3629 - val_accuracy: 0.8240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XsE4-9pzQFd"
      },
      "source": [
        "Salva il modello per poterlo utilizzare per i vari test \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVuZlC0Ey9r2",
        "outputId": "04d9e360-6a72-43dc-ec0f-91ab7526191e"
      },
      "source": [
        "model.save('./Amazon_base_model')"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./Amazon_base_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./Amazon_base_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l7uqq18zMSC"
      },
      "source": [
        "model = keras.models.load_model('Amazon_base_model')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK1qk9NhgLwk"
      },
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(test_reviews, y_test,batch_size=128)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7ia8wvAV_zl"
      },
      "source": [
        "## **OLD**\n",
        "Da non usare in quanto l'embedding viene fatto esterno al modello e non dentro il modello stesso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFwjDO-kfqmz"
      },
      "source": [
        "use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTsFQENXfs1g"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "\r\n",
        "type_one_hot = OneHotEncoder(sparse=False).fit_transform(\r\n",
        "  review_df.review_type.to_numpy().reshape(-1, 1)\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1kJ-hvtfwtT"
      },
      "source": [
        "train_reviews, test_reviews, y_train, y_test =\\\r\n",
        "  train_test_split(\r\n",
        "    review_df.review, \r\n",
        "    type_one_hot, \r\n",
        "    test_size=.1, \r\n",
        "    random_state=RANDOM_SEED\r\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgVcoRPAfy4u"
      },
      "source": [
        "X_train = []\r\n",
        "for r in tqdm(train_reviews):\r\n",
        "  emb = use(r)\r\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\r\n",
        "  X_train.append(review_emb)\r\n",
        "\r\n",
        "X_train = np.array(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVigz3DTfzuI"
      },
      "source": [
        "X_test = []\r\n",
        "for r in tqdm(test_reviews):\r\n",
        "  emb = use(r)\r\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\r\n",
        "  X_test.append(review_emb)\r\n",
        "\r\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42WVLQS53qxf"
      },
      "source": [
        "with open(\"/content/drive/Shareddrives/Deep Learning/datasets/Amazon/X_train.pkl\", 'wb') as output:\r\n",
        "  pickle.dump(X_train, output, protocol=4)\r\n",
        "\r\n",
        "with open(\"/content/drive/Shareddrives/Deep Learning/datasets/Amazon/X_test.pkl\", 'wb') as output:\r\n",
        "  pickle.dump(X_test, output, protocol=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-NeCOf2BkG-"
      },
      "source": [
        "with open(\"/content/drive/Shareddrives/Deep Learning/datasets/Amazon/X_train.pkl\", 'rb') as output:\n",
        "  print(output)\n",
        "  X_train=pickle.load(output)\n",
        "\n",
        "with open(\"/content/drive/Shareddrives/Deep Learning/datasets/Amazon/X_test.pkl\", 'rb') as output:\n",
        "  print(output)\n",
        "  X_test=pickle.load(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD1OiVRvGKI8"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDysgPLAf1wW"
      },
      "source": [
        "model = keras.Sequential()\r\n",
        "\r\n",
        "model.add(keras.layers.Dense(units=256, input_shape=(X_train.shape[1], ), activation='relu'))\r\n",
        "model.add(keras.layers.Dropout(rate=0.2))\r\n",
        "model.add(keras.layers.Dense(units=128, activation='relu'))\r\n",
        "model.add(keras.layers.Dropout(rate=0.2))\r\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8Hmkf9zf4BP"
      },
      "source": [
        "history = model.fit(\r\n",
        "    X_train, y_train, \r\n",
        "    epochs=15, \r\n",
        "    batch_size=16, \r\n",
        "    validation_split=0.1, \r\n",
        "    verbose=1, \r\n",
        "    shuffle=True\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SYpnj9p_SeY"
      },
      "source": [
        "train_reviews[180138]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC-tGAlY7nam"
      },
      "source": [
        "df.iloc[94752].review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xifFnken8US7"
      },
      "source": [
        "review_df.iloc[94752]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5s6AD4789lO"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcxGPz1Sf6Rg"
      },
      "source": [
        "frase=\"s.  His finicky culinary mandates are the most outrageous, unreasonable and demanding of almost any human I\\'ve ever known.  His love of nuts is extremely persnickety, and he has been known to turn his nose up at some of the most expensive gourmet nut selections available.<br />Sunflower Food and Spice Co Honey Toasted Cashews gave me a first ever accomplishment in my gift-giving history with my sibling.  This year, instead of the usual  eh, not really that good actually.  or the one time in 1996 when I got a meh, they\\'re ok I guess.  He said this:<br /><br />Best cashews I\\'ve ever had.<br /><br />Truly, I can not tell you how significant a statement that is.\"\r\n",
        "\r\n",
        "emb_frase=use(frase)\r\n",
        "\r\n",
        "model.predict(emb_frase)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
