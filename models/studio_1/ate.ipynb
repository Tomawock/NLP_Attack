{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-DWn9G8qo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f2154ba-b71e-4389-9637-3d4869c8bbb5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhZgkl4B_XVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c807784-b023-4050-b32d-3eb2cc727daf"
      },
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing collected packages: colorlog, cmaes, Mako, python-editor, alembic, colorama, pyperclip, cmd2, pbr, stevedore, cliff, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.5.8 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-4.8.0 optuna-2.6.0 pbr-5.5.1 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvIOj4268c1y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9omR98sh9v-r"
      },
      "source": [
        "path=\"/content/drive/Shareddrives/Deep Learning/datasets/ATE_ABSITA/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPJoY-GO8suc"
      },
      "source": [
        "test = pd.read_json(path+'ATE_ABSITA_test_set/ate_absita_gold.ndjson',\n",
        "                    lines=True)\n",
        "\n",
        "train = pd.read_json(path+'ATE_ABSITA_training_set/ate_absita_training.ndjson',\n",
        "                     lines=True)\n",
        "\n",
        "data_sinonimi = pd.read_csv(path+\"ATE_ABSITA_test_set/sinonimi.csv\")\n",
        "data_embedding = pd.read_csv(path+\"ATE_ABSITA_test_set/embedding.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bZ02rvT5z8H"
      },
      "source": [
        "# carico e creo dataset per studio 1 \n",
        "sinonimi_to_concat = pd.read_csv(path+\"ATE_ABSITA_training_set/sinonimi.csv\")\n",
        "train_study_1 = pd.concat([train, sinonimi_to_concat], ignore_index=True)\n",
        "test_study_1 = pd.concat([test, data_sinonimi], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1OCMqGV8szX"
      },
      "source": [
        "print(test.columns)\n",
        "print(train.columns)\n",
        "print(data_sinonimi.columns)\n",
        "print(data_embedding.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbAHXJR78s3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ddab51-aa1a-4635-f2e8-e8e799006c1d"
      },
      "source": [
        "train.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "test.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "data_sinonimi.drop(columns=['polarities','aspects_position','aspects'], inplace=True)\n",
        "data_embedding.drop(columns=['polarities','aspects_position','aspects'], inplace=True)\n",
        "print(f'Contains {len(train)} sentences')\n",
        "print(f'Contains {len(test)} sentences')\n",
        "print(f'Contains {len(data_sinonimi)} sentences')\n",
        "print(f'Contains {len(data_embedding)} sentences')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contains 3054 sentences\n",
            "Contains 1200 sentences\n",
            "Contains 1200 sentences\n",
            "Contains 1200 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkR5_q5n6ZbS"
      },
      "source": [
        "# study 1\n",
        "train_study_1.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "test_study_1.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "print(f'Contains {len(train_study_1)} sentences')\n",
        "print(f'Contains {len(test_study_1)} sentences')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iePD6n9p82nG"
      },
      "source": [
        "Creazione colonna Positivi/Negativi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuCtCXCw8s6M"
      },
      "source": [
        "train[\"review_type\"] = train[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "test[\"review_type\"] = test[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "data_sinonimi[\"review_type\"] = data_sinonimi[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "data_embedding[\"review_type\"] = data_embedding[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "\n",
        "print(f'TRAIN::\\n{train.review_type.value_counts()}')\n",
        "print(f'TEST::\\n{test.review_type.value_counts()}')\n",
        "print(f'SINONIMI::\\n{data_sinonimi.review_type.value_counts()}')\n",
        "print(f'EMBEDDING::\\n{data_embedding.review_type.value_counts()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVZ4UU_L6v0E",
        "outputId": "4094c1e0-74dc-4a60-cb68-53cc4957eca0"
      },
      "source": [
        "# study 1\n",
        "train_study_1[\"review_type\"] = train_study_1[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "test_study_1[\"review_type\"] = test_study_1[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "print(f'TRAIN::\\n{train_study_1.review_type.value_counts()}')\n",
        "print(f'TEST::\\n{test_study_1.review_type.value_counts()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN::\n",
            "pos    4300\n",
            "neg    1808\n",
            "Name: review_type, dtype: int64\n",
            "TEST::\n",
            "pos    1714\n",
            "neg     686\n",
            "Name: review_type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru-WHUt788NG"
      },
      "source": [
        "Rimozione Colonna Score in quanto non piu significativa per la Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqPpoik2AJJZ"
      },
      "source": [
        "train.drop(columns=['score'], inplace=True)\n",
        "test.drop(columns=['score'], inplace=True)\n",
        "data_sinonimi.drop(columns=['score'], inplace=True)\n",
        "data_embedding.drop(columns=['score'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeI8hXfS7EEv"
      },
      "source": [
        "# study 1\n",
        "train_study_1.drop(columns=['score'], inplace=True)\n",
        "test_study_1.drop(columns=['score'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTQldsfF8s8_"
      },
      "source": [
        "with open(path+\"word2index.pkl\", 'rb') as output:\n",
        "  w2i = pickle.load(output)\n",
        "with open(path+\"embedding_matrix.pkl\", 'rb') as output:\n",
        "  embedding_matrix = pickle.load(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21BASbk79EIe"
      },
      "source": [
        "Trasformazione input da frasi a vettori di parole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv5nfe958s_s"
      },
      "source": [
        "def my_text_to_word_sequence(sentence):\n",
        "  return keras.preprocessing.text.text_to_word_sequence(sentence,\n",
        "                                                        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`\\'{|}~\\t\\n',\n",
        "                                                        lower=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHcjEZ6j9g_F"
      },
      "source": [
        "TRAIN, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lPd3qFfAqJl"
      },
      "source": [
        "one_hot_train = OneHotEncoder(sparse=False).fit_transform(\n",
        "        train.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_bOaNrp5-9b"
      },
      "source": [
        "sentences = [my_text_to_word_sequence(sentence) for sentence in train['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XbJvMUL7s2h"
      },
      "source": [
        "# study 1\n",
        "one_hot_train_study_1 = OneHotEncoder(sparse=False).fit_transform(\n",
        "        train_study_1.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmO7lD0I7OXR"
      },
      "source": [
        "# study 1\n",
        "sentences_study_1 = [my_text_to_word_sequence(sentence) for sentence in train_study_1['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzm3YxooRiWW"
      },
      "source": [
        "TEST, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqK9OLeoRiWY"
      },
      "source": [
        "one_hot_test = OneHotEncoder(sparse=False).fit_transform(\n",
        "        test.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvsh3KbXRiWY"
      },
      "source": [
        "sentences_test = [my_text_to_word_sequence(sentence) for sentence in test['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgtbtZWM76Z5"
      },
      "source": [
        "# study 1\n",
        "one_hot_test_study_1 = OneHotEncoder(sparse=False).fit_transform(\n",
        "        test_study_1.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOnH57Tu75XT"
      },
      "source": [
        "# study 1\n",
        "sentences_test_study_1 = [my_text_to_word_sequence(sentence) for sentence in test_study_1['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtqBuF4zRi--"
      },
      "source": [
        "SINONIMI, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0sNiYBERi_A"
      },
      "source": [
        "one_hot_sin = OneHotEncoder(sparse=False).fit_transform(\n",
        "        data_sinonimi.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwa-A7qfRi_B"
      },
      "source": [
        "sentences_sin = [my_text_to_word_sequence(sentence) for sentence in data_sinonimi['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrUKHOU9RjeZ"
      },
      "source": [
        "EMBEDDING, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l8HELWMRjea"
      },
      "source": [
        "one_hot_emb = OneHotEncoder(sparse=False).fit_transform(\n",
        "        data_embedding.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pA2ra7HRjeb"
      },
      "source": [
        "sentences_emb = [my_text_to_word_sequence(sentence) for sentence in data_embedding['sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeTE81j_9cOv"
      },
      "source": [
        "Estrai la massima dimensione dell'input in base ai vari dataset considerati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pudlFdxF8tCA",
        "outputId": "e15a846e-1103-4c1a-d115-a18ccbf2ca6e"
      },
      "source": [
        "max_index, max = (-1, -1)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "\n",
        "# study 1\n",
        "for i, sentence in enumerate(sentences_study_1):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_test_study_1):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "\n",
        "\n",
        "print(f'Il massimo è {max}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il massimo è 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbKTvQuOEaP3"
      },
      "source": [
        "Creo i vari embedding per tutti i dataset, quest'operazione e pesante "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfA2XQzE9hdL"
      },
      "source": [
        "embedded_train = np.zeros(shape=(len(sentences), max, 300))\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_train[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZW78yxjTJly"
      },
      "source": [
        "embedded_test = np.zeros(shape=(len(sentences_test), max, 300))\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_test[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkN3_ZGQTK49"
      },
      "source": [
        "embedded_sin = np.zeros(shape=(len(sentences_sin), max, 300))\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_sin[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcf1fth5TLGy"
      },
      "source": [
        "embedded_emb = np.zeros(shape=(len(sentences_emb), max, 300))\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_emb[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfy0ur_5-mMx"
      },
      "source": [
        "# study 1\n",
        "embedded_train_study_1 = np.zeros(shape=(len(sentences_study_1), max, 300))\n",
        "for i, sentence in enumerate(sentences_study_1):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_train_study_1[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwaZXvkY_Ak3"
      },
      "source": [
        "# study 1\n",
        "embedded_test_study_1 = np.zeros(shape=(len(sentences_test_study_1), max, 300))\n",
        "for i, sentence in enumerate(sentences_test_study_1):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_test_study_1[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5rb4COz9oVn"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IHhcxg49qg5"
      },
      "source": [
        "best_params = optuna.load_study(study_name=\"ATE\", storage=\"sqlite:///\"+path+\"optuna_ATE_studio_0.db\").best_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM6k1Bf08TJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47ca409-0e9d-45cc-9701-c9aec2747cfd"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Input(shape=(max, 300)))\n",
        "model.add(keras.layers.Bidirectional(layer=keras.layers.LSTM(units=best_params[\"units\"],\n",
        "                                                             recurrent_dropout=best_params[\"dropout\"],\n",
        "                                                             activation='tanh')))\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=keras.optimizers.Adam(0.001),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2X4fzLwFwls",
        "outputId": "0fdce9a1-5468-4c67-9a29-21650c4d2307"
      },
      "source": [
        "best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 55, 'dropout': 0.28, 'units': 125}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8t68xO9BMmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61ae0bd-b72a-435c-859f-0fa7e8e15e04"
      },
      "source": [
        "#train model\n",
        "\n",
        "#embedded_* è il nome da cambiare per allenare il modello sul dataseta selezionato per lo studio in esame\n",
        "\n",
        "#one_hot_* è il nome dell'encoding delle parole del dataseta selezionato per lo studio in esame\n",
        "result = model.fit(embedded_train_study_1,\n",
        "                 one_hot_train_study_1,\n",
        "                 epochs=100,\n",
        "                 batch_size=best_params[\"batch_size\"],\n",
        "                 callbacks=[keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                            patience=10)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 81s 667ms/step - loss: 0.6103 - accuracy: 0.7059\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 73s 656ms/step - loss: 0.5448 - accuracy: 0.7298\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 74s 660ms/step - loss: 0.5115 - accuracy: 0.7468\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 74s 661ms/step - loss: 0.4839 - accuracy: 0.7693\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 74s 660ms/step - loss: 0.4663 - accuracy: 0.7816\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 73s 653ms/step - loss: 0.4454 - accuracy: 0.7941\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 72s 644ms/step - loss: 0.4251 - accuracy: 0.8042\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.4033 - accuracy: 0.8255\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 73s 653ms/step - loss: 0.3643 - accuracy: 0.8373\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 73s 656ms/step - loss: 0.3455 - accuracy: 0.8510\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 74s 658ms/step - loss: 0.2940 - accuracy: 0.8798\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 74s 657ms/step - loss: 0.2679 - accuracy: 0.8877\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 73s 655ms/step - loss: 0.2489 - accuracy: 0.8990\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 73s 654ms/step - loss: 0.2545 - accuracy: 0.8926\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 73s 653ms/step - loss: 0.4223 - accuracy: 0.8165\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 73s 649ms/step - loss: 0.3056 - accuracy: 0.8660\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.2231 - accuracy: 0.9123\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 73s 651ms/step - loss: 0.1886 - accuracy: 0.9238\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.1855 - accuracy: 0.9239\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 73s 649ms/step - loss: 0.2071 - accuracy: 0.9225\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 73s 649ms/step - loss: 0.1345 - accuracy: 0.9519\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 73s 651ms/step - loss: 0.1409 - accuracy: 0.9448\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 72s 646ms/step - loss: 0.1150 - accuracy: 0.9595\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 73s 651ms/step - loss: 0.1972 - accuracy: 0.9216\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 74s 657ms/step - loss: 0.1069 - accuracy: 0.9599\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 72s 646ms/step - loss: 0.0957 - accuracy: 0.9629\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 72s 644ms/step - loss: 0.0854 - accuracy: 0.9706\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 72s 645ms/step - loss: 0.0924 - accuracy: 0.9634\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 72s 645ms/step - loss: 0.0961 - accuracy: 0.9611\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 72s 644ms/step - loss: 0.0765 - accuracy: 0.9708\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.0817 - accuracy: 0.9689\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 74s 659ms/step - loss: 0.0803 - accuracy: 0.9726\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.0591 - accuracy: 0.9784\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 72s 643ms/step - loss: 0.0657 - accuracy: 0.9760\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 72s 643ms/step - loss: 0.0707 - accuracy: 0.9762\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 72s 647ms/step - loss: 0.0695 - accuracy: 0.9746\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.0843 - accuracy: 0.9668\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 73s 650ms/step - loss: 0.0555 - accuracy: 0.9815\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 73s 656ms/step - loss: 0.0442 - accuracy: 0.9853\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 75s 665ms/step - loss: 0.0549 - accuracy: 0.9809\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 72s 646ms/step - loss: 0.0461 - accuracy: 0.9845\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 73s 652ms/step - loss: 0.0480 - accuracy: 0.9822\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.1174 - accuracy: 0.9579\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 72s 645ms/step - loss: 0.0463 - accuracy: 0.9844\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 72s 646ms/step - loss: 0.0339 - accuracy: 0.9879\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 72s 647ms/step - loss: 0.0339 - accuracy: 0.9892\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 72s 646ms/step - loss: 0.1284 - accuracy: 0.9540\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 73s 649ms/step - loss: 0.0394 - accuracy: 0.9872\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 72s 645ms/step - loss: 0.0346 - accuracy: 0.9895\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 73s 655ms/step - loss: 0.0352 - accuracy: 0.9891\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 75s 671ms/step - loss: 0.0342 - accuracy: 0.9889\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 74s 664ms/step - loss: 0.0400 - accuracy: 0.9882\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 73s 653ms/step - loss: 0.0400 - accuracy: 0.9865\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.0323 - accuracy: 0.9894\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 72s 647ms/step - loss: 0.0393 - accuracy: 0.9879\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 73s 654ms/step - loss: 0.0329 - accuracy: 0.9908\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 73s 650ms/step - loss: 0.0255 - accuracy: 0.9899\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 73s 651ms/step - loss: 0.0181 - accuracy: 0.9942\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 72s 642ms/step - loss: 0.0206 - accuracy: 0.9932\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 72s 643ms/step - loss: 0.0174 - accuracy: 0.9945\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 72s 643ms/step - loss: 0.0235 - accuracy: 0.9928\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 72s 640ms/step - loss: 0.0224 - accuracy: 0.9941\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 72s 644ms/step - loss: 0.0308 - accuracy: 0.9902\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 71s 638ms/step - loss: 0.0280 - accuracy: 0.9914\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 72s 638ms/step - loss: 0.0331 - accuracy: 0.9881\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 72s 646ms/step - loss: 0.0286 - accuracy: 0.9899\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.0251 - accuracy: 0.9935\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 72s 644ms/step - loss: 0.0183 - accuracy: 0.9951\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 71s 636ms/step - loss: 0.0171 - accuracy: 0.9943\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 72s 644ms/step - loss: 0.0160 - accuracy: 0.9952\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 71s 636ms/step - loss: 0.0137 - accuracy: 0.9958\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 71s 635ms/step - loss: 0.0191 - accuracy: 0.9952\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 72s 642ms/step - loss: 0.0197 - accuracy: 0.9929\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 72s 642ms/step - loss: 0.0238 - accuracy: 0.9925\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 71s 635ms/step - loss: 0.0213 - accuracy: 0.9944\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 72s 643ms/step - loss: 0.0168 - accuracy: 0.9947\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 72s 641ms/step - loss: 0.0167 - accuracy: 0.9950\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 72s 639ms/step - loss: 0.0261 - accuracy: 0.9892\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 71s 638ms/step - loss: 0.0209 - accuracy: 0.9933\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 72s 638ms/step - loss: 0.0107 - accuracy: 0.9959\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 72s 646ms/step - loss: 0.0080 - accuracy: 0.9982\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 74s 661ms/step - loss: 0.0143 - accuracy: 0.9942\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 74s 659ms/step - loss: 0.0151 - accuracy: 0.9959\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 73s 651ms/step - loss: 0.0088 - accuracy: 0.9982\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 73s 648ms/step - loss: 0.0121 - accuracy: 0.9958\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 73s 652ms/step - loss: 0.0194 - accuracy: 0.9940\n",
            "Epoch 87/100\n",
            "112/112 [==============================] - 72s 643ms/step - loss: 0.0148 - accuracy: 0.9962\n",
            "Epoch 88/100\n",
            "112/112 [==============================] - 72s 643ms/step - loss: 0.0292 - accuracy: 0.9897\n",
            "Epoch 89/100\n",
            "112/112 [==============================] - 73s 653ms/step - loss: 0.0144 - accuracy: 0.9952\n",
            "Epoch 90/100\n",
            "112/112 [==============================] - 73s 652ms/step - loss: 0.0197 - accuracy: 0.9941\n",
            "Epoch 91/100\n",
            "112/112 [==============================] - 72s 642ms/step - loss: 0.0154 - accuracy: 0.9951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbstjV0B9qmF"
      },
      "source": [
        "#save the model\n",
        "# cambiare il nome in base allo studio che si svolge\n",
        "model.save_weights(path+'ATE_w_studio_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmdfbdbGBQMT"
      },
      "source": [
        "# cambiare il nome in base allo studio che si svolge\n",
        "model.load_weights(path+'ATE_w_studio_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Y6MEPfCRC-"
      },
      "source": [
        "#EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nWACJzvHyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095a32bc-97c6-49d8-f973-197c4c9b98fe"
      },
      "source": [
        "# da ignorare per lo studio 1\n",
        "result_base=model.evaluate(embedded_trainset,one_hot_train,batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET ORIGINARIO{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 3s 42ms/step - loss: 1.7612 - accuracy: 0.6811\n",
            "DATASET ORIGINARIO[1.7612053155899048, 0.6810740232467651]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjcdAwqeOi7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01145014-472f-4b37-f2bc-5a0ce4e15b90"
      },
      "source": [
        "result_base=model.evaluate(embedded_test,one_hot_test,batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET DEV{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 3s 88ms/step - loss: 2.1503 - accuracy: 0.6675\n",
            "DATASET DEV[2.1502692699432373, 0.6675000190734863]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuaVK__WOjDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d584adee-12d7-4b85-9bbd-0f6101383485"
      },
      "source": [
        "result_base=model.evaluate(embedded_sin,one_hot_sin,batch_size=best_params['batch_size'])\n",
        "print(f'DATASET SINONIMI{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 2s 82ms/step - loss: 2.1924 - accuracy: 0.6675\n",
            "DATASET SINONIMI[2.1924490928649902, 0.6675000190734863]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JgLKE2bOjLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2ad29a-31f6-45b3-a224-0627264b5dae"
      },
      "source": [
        "result_base=model.evaluate(embedded_emb,one_hot_emb,batch_size=best_params['batch_size'])\n",
        "print(f'DATASET EMBEDDING{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 2s 83ms/step - loss: 2.3464 - accuracy: 0.6458\n",
            "DATASET EMBEDDING[2.3464369773864746, 0.6458333134651184]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkCNsSHVOV8v",
        "outputId": "00fe2a34-5a53-44b8-ad98-3ee678ee7474"
      },
      "source": [
        "# aggiunta per studio 1\n",
        "result_base=model.evaluate(embedded_test_study_1,one_hot_test_study_1,batch_size=best_params['batch_size'])\n",
        "print(f'DATASET TEST+TEST_SINONIMI{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 4s 82ms/step - loss: 2.1714 - accuracy: 0.6675\n",
            "DATASET TEST+TEST_SINONIMI[2.1713595390319824, 0.6675000190734863]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}