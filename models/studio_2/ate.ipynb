{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ate studio 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-DWn9G8qo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9a1d97-3794-4498-a779-29ab0ac4cf64"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhZgkl4B_XVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bc427f-37be-483c-c486-dbb2e932eae5"
      },
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/21/d13081805e1e1afc71f5bb743ece324c8bd576237c51b899ecb38a717502/optuna-2.7.0-py3-none-any.whl (293kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 22.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 40kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 174kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 194kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 204kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 215kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 225kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 235kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 245kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 256kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 266kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 276kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 286kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/51/62/61449c6bb74c2a3953c415b2cdb488e4f0518ac67b35e2b03a6d543035ca/colorlog-4.8.0-py2.py3-none-any.whl\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/a4/97eb6273839655cac14947986fa7a5935350fcfd4fff872e9654264c82d8/alembic-1.5.8-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/d6/7d9acb68a77acd140be7fececb7f2701b2a29d2da9c54184cb8f93509590/cliff-3.7.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.3)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 14.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/15061b32332bb35ea2a2f6263d0f616779d576e82739ec8e7fcf3c94abf5/cmd2-1.5.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.7.4.3)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11107 sha256=352c51d9e36cbf9c546741f75eab9495d33c58ab39409c168aefe79f2480cfa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: colorlog, cmaes, python-editor, Mako, alembic, pbr, stevedore, colorama, pyperclip, cmd2, cliff, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.5.8 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-4.8.0 optuna-2.7.0 pbr-5.5.1 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvIOj4268c1y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9omR98sh9v-r"
      },
      "source": [
        "path=\"/content/drive/Shareddrives/Deep Learning/datasets/ATE_ABSITA/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPJoY-GO8suc"
      },
      "source": [
        "test = pd.read_json(path+'ATE_ABSITA_test_set/ate_absita_gold.ndjson',\n",
        "                    lines=True)\n",
        "\n",
        "train = pd.read_json(path+'ATE_ABSITA_training_set/ate_absita_training.ndjson',\n",
        "                     lines=True)\n",
        "\n",
        "data_sinonimi = pd.read_csv(path+\"ATE_ABSITA_test_set/sinonimi.csv\")\n",
        "data_embedding = pd.read_csv(path+\"ATE_ABSITA_test_set/embedding.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bZ02rvT5z8H"
      },
      "source": [
        "# carico e creo dataset per studio 2, anche se le variabili si chiamano ...study_1 \n",
        "embedding_to_concat = pd.read_csv(path+\"ATE_ABSITA_training_set/embedding.csv\")\n",
        "train_study_1 = pd.concat([train, embedding_to_concat], ignore_index=True)\n",
        "test_study_1 = pd.concat([test, data_embedding], ignore_index=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1OCMqGV8szX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f0eacd-d0dc-4c17-9b33-7ff80a972876"
      },
      "source": [
        "print(test.columns)\n",
        "print(train.columns)\n",
        "print(data_sinonimi.columns)\n",
        "print(data_embedding.columns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['sentence', 'id_sentence', 'score', 'polarities', 'aspects_position',\n",
            "       'aspects'],\n",
            "      dtype='object')\n",
            "Index(['sentence', 'id_sentence', 'score', 'polarities', 'aspects_position',\n",
            "       'aspects'],\n",
            "      dtype='object')\n",
            "Index(['sentence', 'score', 'polarities', 'aspects_position', 'aspects'], dtype='object')\n",
            "Index(['sentence', 'score', 'polarities', 'aspects_position', 'aspects'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbAHXJR78s3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511c3878-fecc-496b-de0f-bab7ebc69c8b"
      },
      "source": [
        "train.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "test.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "data_sinonimi.drop(columns=['polarities','aspects_position','aspects'], inplace=True)\n",
        "data_embedding.drop(columns=['polarities','aspects_position','aspects'], inplace=True)\n",
        "print(f'Contains {len(train)} sentences')\n",
        "print(f'Contains {len(test)} sentences')\n",
        "print(f'Contains {len(data_sinonimi)} sentences')\n",
        "print(f'Contains {len(data_embedding)} sentences')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contains 3054 sentences\n",
            "Contains 1200 sentences\n",
            "Contains 1200 sentences\n",
            "Contains 1200 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkR5_q5n6ZbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df30b6f-d789-4175-f9a6-5c754f3541e5"
      },
      "source": [
        "# study 1\n",
        "train_study_1.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "test_study_1.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
        "print(f'Contains {len(train_study_1)} sentences')\n",
        "print(f'Contains {len(test_study_1)} sentences')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contains 6108 sentences\n",
            "Contains 2400 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iePD6n9p82nG"
      },
      "source": [
        "Creazione colonna Positivi/Negativi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuCtCXCw8s6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19693c92-d826-494b-c3c7-9d4d4780a704"
      },
      "source": [
        "train[\"review_type\"] = train[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "test[\"review_type\"] = test[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "data_sinonimi[\"review_type\"] = data_sinonimi[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "data_embedding[\"review_type\"] = data_embedding[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "\n",
        "print(f'TRAIN::\\n{train.review_type.value_counts()}')\n",
        "print(f'TEST::\\n{test.review_type.value_counts()}')\n",
        "print(f'SINONIMI::\\n{data_sinonimi.review_type.value_counts()}')\n",
        "print(f'EMBEDDING::\\n{data_embedding.review_type.value_counts()}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN::\n",
            "pos    2150\n",
            "neg     904\n",
            "Name: review_type, dtype: int64\n",
            "TEST::\n",
            "pos    857\n",
            "neg    343\n",
            "Name: review_type, dtype: int64\n",
            "SINONIMI::\n",
            "pos    857\n",
            "neg    343\n",
            "Name: review_type, dtype: int64\n",
            "EMBEDDING::\n",
            "pos    857\n",
            "neg    343\n",
            "Name: review_type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVZ4UU_L6v0E",
        "outputId": "033e635a-c07c-4139-fdf5-f577edf070df"
      },
      "source": [
        "# study 1\n",
        "train_study_1[\"review_type\"] = train_study_1[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "test_study_1[\"review_type\"] = test_study_1[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
        "print(f'TRAIN::\\n{train_study_1.review_type.value_counts()}')\n",
        "print(f'TEST::\\n{test_study_1.review_type.value_counts()}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN::\n",
            "pos    4300\n",
            "neg    1808\n",
            "Name: review_type, dtype: int64\n",
            "TEST::\n",
            "pos    1714\n",
            "neg     686\n",
            "Name: review_type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru-WHUt788NG"
      },
      "source": [
        "Rimozione Colonna Score in quanto non piu significativa per la Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqPpoik2AJJZ"
      },
      "source": [
        "train.drop(columns=['score'], inplace=True)\n",
        "test.drop(columns=['score'], inplace=True)\n",
        "data_sinonimi.drop(columns=['score'], inplace=True)\n",
        "data_embedding.drop(columns=['score'], inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeI8hXfS7EEv"
      },
      "source": [
        "# study 1\n",
        "train_study_1.drop(columns=['score'], inplace=True)\n",
        "test_study_1.drop(columns=['score'], inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTQldsfF8s8_"
      },
      "source": [
        "with open(path+\"word2index.pkl\", 'rb') as output:\n",
        "  w2i = pickle.load(output)\n",
        "with open(path+\"embedding_matrix.pkl\", 'rb') as output:\n",
        "  embedding_matrix = pickle.load(output)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21BASbk79EIe"
      },
      "source": [
        "Trasformazione input da frasi a vettori di parole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv5nfe958s_s"
      },
      "source": [
        "def my_text_to_word_sequence(sentence):\n",
        "  return keras.preprocessing.text.text_to_word_sequence(sentence,\n",
        "                                                        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`\\'{|}~\\t\\n',\n",
        "                                                        lower=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHcjEZ6j9g_F"
      },
      "source": [
        "TRAIN, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lPd3qFfAqJl"
      },
      "source": [
        "one_hot_train = OneHotEncoder(sparse=False).fit_transform(\n",
        "        train.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_bOaNrp5-9b"
      },
      "source": [
        "sentences = [my_text_to_word_sequence(sentence) for sentence in train['sentence']]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XbJvMUL7s2h"
      },
      "source": [
        "# study 1\n",
        "one_hot_train_study_1 = OneHotEncoder(sparse=False).fit_transform(\n",
        "        train_study_1.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmO7lD0I7OXR"
      },
      "source": [
        "# study 1\n",
        "sentences_study_1 = [my_text_to_word_sequence(sentence) for sentence in train_study_1['sentence']]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzm3YxooRiWW"
      },
      "source": [
        "TEST, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqK9OLeoRiWY"
      },
      "source": [
        "one_hot_test = OneHotEncoder(sparse=False).fit_transform(\n",
        "        test.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvsh3KbXRiWY"
      },
      "source": [
        "sentences_test = [my_text_to_word_sequence(sentence) for sentence in test['sentence']]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgtbtZWM76Z5"
      },
      "source": [
        "# study 1\n",
        "one_hot_test_study_1 = OneHotEncoder(sparse=False).fit_transform(\n",
        "        test_study_1.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOnH57Tu75XT"
      },
      "source": [
        "# study 1\n",
        "sentences_test_study_1 = [my_text_to_word_sequence(sentence) for sentence in test_study_1['sentence']]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtqBuF4zRi--"
      },
      "source": [
        "SINONIMI, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0sNiYBERi_A"
      },
      "source": [
        "one_hot_sin = OneHotEncoder(sparse=False).fit_transform(\n",
        "        data_sinonimi.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwa-A7qfRi_B"
      },
      "source": [
        "sentences_sin = [my_text_to_word_sequence(sentence) for sentence in data_sinonimi['sentence']]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrUKHOU9RjeZ"
      },
      "source": [
        "EMBEDDING, Encoding e Dataset per modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l8HELWMRjea"
      },
      "source": [
        "one_hot_emb = OneHotEncoder(sparse=False).fit_transform(\n",
        "        data_embedding.review_type.to_numpy().reshape(-1, 1)\n",
        "        )"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pA2ra7HRjeb"
      },
      "source": [
        "sentences_emb = [my_text_to_word_sequence(sentence) for sentence in data_embedding['sentence']]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeTE81j_9cOv"
      },
      "source": [
        "Estrai la massima dimensione dell'input in base ai vari dataset considerati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pudlFdxF8tCA",
        "outputId": "913c9828-da8c-40a1-ef1f-c4bfc465d00c"
      },
      "source": [
        "max_index, max = (-1, -1)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "\n",
        "# study 1\n",
        "for i, sentence in enumerate(sentences_study_1):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "for i, sentence in enumerate(sentences_test_study_1):\n",
        "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
        "\n",
        "\n",
        "print(f'Il massimo è {max}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Il massimo è 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbKTvQuOEaP3"
      },
      "source": [
        "Creo i vari embedding per tutti i dataset, quest'operazione e pesante "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfA2XQzE9hdL"
      },
      "source": [
        "embedded_train = np.zeros(shape=(len(sentences), max, 300))\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_train[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZW78yxjTJly"
      },
      "source": [
        "embedded_test = np.zeros(shape=(len(sentences_test), max, 300))\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_test[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkN3_ZGQTK49"
      },
      "source": [
        "embedded_sin = np.zeros(shape=(len(sentences_sin), max, 300))\n",
        "for i, sentence in enumerate(sentences_sin):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_sin[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcf1fth5TLGy"
      },
      "source": [
        "embedded_emb = np.zeros(shape=(len(sentences_emb), max, 300))\n",
        "for i, sentence in enumerate(sentences_emb):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_emb[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfy0ur_5-mMx"
      },
      "source": [
        "# study 1\n",
        "embedded_train_study_1 = np.zeros(shape=(len(sentences_study_1), max, 300))\n",
        "for i, sentence in enumerate(sentences_study_1):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_train_study_1[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwaZXvkY_Ak3"
      },
      "source": [
        "# study 1\n",
        "embedded_test_study_1 = np.zeros(shape=(len(sentences_test_study_1), max, 300))\n",
        "for i, sentence in enumerate(sentences_test_study_1):\n",
        "  for j, word in enumerate(sentence):\n",
        "    try:\n",
        "      embedded_test_study_1[i, j, :] = embedding_matrix[w2i[word]]\n",
        "    except KeyError:\n",
        "      pass"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5rb4COz9oVn"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IHhcxg49qg5"
      },
      "source": [
        "best_params = optuna.load_study(study_name=\"ATE\", storage=\"sqlite:///\"+path+\"optuna_ATE_studio_0.db\").best_params"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM6k1Bf08TJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f836ec-dec2-4465-e38f-67226289c17a"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Input(shape=(max, 300)))\n",
        "model.add(keras.layers.Bidirectional(layer=keras.layers.LSTM(units=best_params[\"units\"],\n",
        "                                                             recurrent_dropout=best_params[\"dropout\"],\n",
        "                                                             activation='tanh')))\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=keras.optimizers.Adam(0.001),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2X4fzLwFwls",
        "outputId": "356ff929-fbac-4084-b069-038ac381bba5"
      },
      "source": [
        "best_params"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 55, 'dropout': 0.28, 'units': 125}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8t68xO9BMmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034f5635-730d-4a6c-db0d-0a1967ecf5ee"
      },
      "source": [
        "#train model\n",
        "\n",
        "#embedded_* è il nome da cambiare per allenare il modello sul dataseta selezionato per lo studio in esame\n",
        "\n",
        "#one_hot_* è il nome dell'encoding delle parole del dataseta selezionato per lo studio in esame\n",
        "result = model.fit(embedded_train_study_1,\n",
        "                 one_hot_train_study_1,\n",
        "                 epochs=100,\n",
        "                 batch_size=best_params[\"batch_size\"],\n",
        "                 callbacks=[keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                            patience=10)])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - 58s 464ms/step - loss: 0.6129 - accuracy: 0.7083\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - 51s 458ms/step - loss: 0.5584 - accuracy: 0.7223\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - 51s 457ms/step - loss: 0.5354 - accuracy: 0.7378\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - 51s 455ms/step - loss: 0.5143 - accuracy: 0.7485\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - 51s 457ms/step - loss: 0.5018 - accuracy: 0.7524\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - 50s 449ms/step - loss: 0.4931 - accuracy: 0.7637\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - 50s 447ms/step - loss: 0.4788 - accuracy: 0.7716\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - 50s 447ms/step - loss: 0.4429 - accuracy: 0.7942\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - 50s 449ms/step - loss: 0.4200 - accuracy: 0.8086\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - 51s 452ms/step - loss: 0.4045 - accuracy: 0.8158\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - 50s 450ms/step - loss: 0.3956 - accuracy: 0.8186\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - 51s 453ms/step - loss: 0.3691 - accuracy: 0.8341\n",
            "Epoch 13/100\n",
            "112/112 [==============================] - 50s 446ms/step - loss: 0.3453 - accuracy: 0.8528\n",
            "Epoch 14/100\n",
            "112/112 [==============================] - 50s 450ms/step - loss: 0.3224 - accuracy: 0.8632\n",
            "Epoch 15/100\n",
            "112/112 [==============================] - 50s 450ms/step - loss: 0.2985 - accuracy: 0.8758\n",
            "Epoch 16/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.2691 - accuracy: 0.8891\n",
            "Epoch 17/100\n",
            "112/112 [==============================] - 51s 453ms/step - loss: 0.2535 - accuracy: 0.9002\n",
            "Epoch 18/100\n",
            "112/112 [==============================] - 51s 453ms/step - loss: 0.2336 - accuracy: 0.9105\n",
            "Epoch 19/100\n",
            "112/112 [==============================] - 49s 441ms/step - loss: 0.2338 - accuracy: 0.9049\n",
            "Epoch 20/100\n",
            "112/112 [==============================] - 51s 453ms/step - loss: 0.2264 - accuracy: 0.9097\n",
            "Epoch 21/100\n",
            "112/112 [==============================] - 52s 466ms/step - loss: 0.1889 - accuracy: 0.9284\n",
            "Epoch 22/100\n",
            "112/112 [==============================] - 51s 456ms/step - loss: 0.1744 - accuracy: 0.9323\n",
            "Epoch 23/100\n",
            "112/112 [==============================] - 52s 460ms/step - loss: 0.1899 - accuracy: 0.9252\n",
            "Epoch 24/100\n",
            "112/112 [==============================] - 51s 458ms/step - loss: 0.1450 - accuracy: 0.9462\n",
            "Epoch 25/100\n",
            "112/112 [==============================] - 52s 462ms/step - loss: 0.1338 - accuracy: 0.9526\n",
            "Epoch 26/100\n",
            "112/112 [==============================] - 51s 456ms/step - loss: 0.1241 - accuracy: 0.9546\n",
            "Epoch 27/100\n",
            "112/112 [==============================] - 51s 457ms/step - loss: 0.1441 - accuracy: 0.9436\n",
            "Epoch 28/100\n",
            "112/112 [==============================] - 51s 452ms/step - loss: 0.1020 - accuracy: 0.9619\n",
            "Epoch 29/100\n",
            "112/112 [==============================] - 50s 449ms/step - loss: 0.1105 - accuracy: 0.9573\n",
            "Epoch 30/100\n",
            "112/112 [==============================] - 51s 451ms/step - loss: 0.0925 - accuracy: 0.9678\n",
            "Epoch 31/100\n",
            "112/112 [==============================] - 50s 444ms/step - loss: 0.1126 - accuracy: 0.9579\n",
            "Epoch 32/100\n",
            "112/112 [==============================] - 50s 447ms/step - loss: 0.0896 - accuracy: 0.9689\n",
            "Epoch 33/100\n",
            "112/112 [==============================] - 50s 446ms/step - loss: 0.0882 - accuracy: 0.9675\n",
            "Epoch 34/100\n",
            "112/112 [==============================] - 50s 447ms/step - loss: 0.0865 - accuracy: 0.9686\n",
            "Epoch 35/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0692 - accuracy: 0.9779\n",
            "Epoch 36/100\n",
            "112/112 [==============================] - 50s 444ms/step - loss: 0.0853 - accuracy: 0.9676\n",
            "Epoch 37/100\n",
            "112/112 [==============================] - 50s 443ms/step - loss: 0.1148 - accuracy: 0.9572\n",
            "Epoch 38/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0708 - accuracy: 0.9761\n",
            "Epoch 39/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0583 - accuracy: 0.9799\n",
            "Epoch 40/100\n",
            "112/112 [==============================] - 50s 446ms/step - loss: 0.0717 - accuracy: 0.9755\n",
            "Epoch 41/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0549 - accuracy: 0.9812\n",
            "Epoch 42/100\n",
            "112/112 [==============================] - 50s 451ms/step - loss: 0.0661 - accuracy: 0.9798\n",
            "Epoch 43/100\n",
            "112/112 [==============================] - 50s 448ms/step - loss: 0.0614 - accuracy: 0.9789\n",
            "Epoch 44/100\n",
            "112/112 [==============================] - 50s 444ms/step - loss: 0.0490 - accuracy: 0.9850\n",
            "Epoch 45/100\n",
            "112/112 [==============================] - 50s 443ms/step - loss: 0.0437 - accuracy: 0.9845\n",
            "Epoch 46/100\n",
            "112/112 [==============================] - 50s 444ms/step - loss: 0.0455 - accuracy: 0.9852\n",
            "Epoch 47/100\n",
            "112/112 [==============================] - 50s 443ms/step - loss: 0.0414 - accuracy: 0.9891\n",
            "Epoch 48/100\n",
            "112/112 [==============================] - 50s 443ms/step - loss: 0.0521 - accuracy: 0.9829\n",
            "Epoch 49/100\n",
            "112/112 [==============================] - 50s 446ms/step - loss: 0.0407 - accuracy: 0.9854\n",
            "Epoch 50/100\n",
            "112/112 [==============================] - 50s 447ms/step - loss: 0.0563 - accuracy: 0.9799\n",
            "Epoch 51/100\n",
            "112/112 [==============================] - 50s 446ms/step - loss: 0.0423 - accuracy: 0.9830\n",
            "Epoch 52/100\n",
            "112/112 [==============================] - 50s 442ms/step - loss: 0.1127 - accuracy: 0.9615\n",
            "Epoch 53/100\n",
            "112/112 [==============================] - 50s 444ms/step - loss: 0.0478 - accuracy: 0.9839\n",
            "Epoch 54/100\n",
            "112/112 [==============================] - 49s 441ms/step - loss: 0.0550 - accuracy: 0.9825\n",
            "Epoch 55/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0288 - accuracy: 0.9921\n",
            "Epoch 56/100\n",
            "112/112 [==============================] - 50s 446ms/step - loss: 0.0295 - accuracy: 0.9908\n",
            "Epoch 57/100\n",
            "112/112 [==============================] - 49s 441ms/step - loss: 0.0315 - accuracy: 0.9899\n",
            "Epoch 58/100\n",
            "112/112 [==============================] - 50s 448ms/step - loss: 0.0439 - accuracy: 0.9838\n",
            "Epoch 59/100\n",
            "112/112 [==============================] - 50s 443ms/step - loss: 0.0314 - accuracy: 0.9908\n",
            "Epoch 60/100\n",
            "112/112 [==============================] - 50s 449ms/step - loss: 0.0932 - accuracy: 0.9654\n",
            "Epoch 61/100\n",
            "112/112 [==============================] - 50s 447ms/step - loss: 0.0270 - accuracy: 0.9930\n",
            "Epoch 62/100\n",
            "112/112 [==============================] - 50s 446ms/step - loss: 0.0304 - accuracy: 0.9890\n",
            "Epoch 63/100\n",
            "112/112 [==============================] - 49s 440ms/step - loss: 0.0239 - accuracy: 0.9936\n",
            "Epoch 64/100\n",
            "112/112 [==============================] - 50s 442ms/step - loss: 0.0240 - accuracy: 0.9930\n",
            "Epoch 65/100\n",
            "112/112 [==============================] - 50s 443ms/step - loss: 0.0323 - accuracy: 0.9885\n",
            "Epoch 66/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0259 - accuracy: 0.9922\n",
            "Epoch 67/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0357 - accuracy: 0.9869\n",
            "Epoch 68/100\n",
            "112/112 [==============================] - 49s 442ms/step - loss: 0.0403 - accuracy: 0.9825\n",
            "Epoch 69/100\n",
            "112/112 [==============================] - 50s 444ms/step - loss: 0.0303 - accuracy: 0.9900\n",
            "Epoch 70/100\n",
            "112/112 [==============================] - 51s 452ms/step - loss: 0.0180 - accuracy: 0.9950\n",
            "Epoch 71/100\n",
            "112/112 [==============================] - 49s 440ms/step - loss: 0.0219 - accuracy: 0.9934\n",
            "Epoch 72/100\n",
            "112/112 [==============================] - 50s 444ms/step - loss: 0.0176 - accuracy: 0.9953\n",
            "Epoch 73/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0308 - accuracy: 0.9891\n",
            "Epoch 74/100\n",
            "112/112 [==============================] - 52s 460ms/step - loss: 0.0343 - accuracy: 0.9904\n",
            "Epoch 75/100\n",
            "112/112 [==============================] - 51s 453ms/step - loss: 0.0358 - accuracy: 0.9848\n",
            "Epoch 76/100\n",
            "112/112 [==============================] - 51s 451ms/step - loss: 0.0172 - accuracy: 0.9949\n",
            "Epoch 77/100\n",
            "112/112 [==============================] - 51s 451ms/step - loss: 0.0158 - accuracy: 0.9951\n",
            "Epoch 78/100\n",
            "112/112 [==============================] - 50s 451ms/step - loss: 0.0157 - accuracy: 0.9934\n",
            "Epoch 79/100\n",
            "112/112 [==============================] - 50s 448ms/step - loss: 0.0172 - accuracy: 0.9960\n",
            "Epoch 80/100\n",
            "112/112 [==============================] - 51s 456ms/step - loss: 0.0135 - accuracy: 0.9961\n",
            "Epoch 81/100\n",
            "112/112 [==============================] - 51s 452ms/step - loss: 0.0238 - accuracy: 0.9924\n",
            "Epoch 82/100\n",
            "112/112 [==============================] - 50s 450ms/step - loss: 0.0190 - accuracy: 0.9949\n",
            "Epoch 83/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0209 - accuracy: 0.9938\n",
            "Epoch 84/100\n",
            "112/112 [==============================] - 50s 442ms/step - loss: 0.0211 - accuracy: 0.9940\n",
            "Epoch 85/100\n",
            "112/112 [==============================] - 50s 448ms/step - loss: 0.0276 - accuracy: 0.9916\n",
            "Epoch 86/100\n",
            "112/112 [==============================] - 50s 445ms/step - loss: 0.0343 - accuracy: 0.9892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbstjV0B9qmF"
      },
      "source": [
        "#save the model\n",
        "# cambiare il nome in base allo studio che si svolge\n",
        "model.save_weights(path+'ATE_w_studio_2.h5')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmdfbdbGBQMT"
      },
      "source": [
        "# cambiare il nome in base allo studio che si svolge\n",
        "model.load_weights(path+'ATE_w_studio_2.h5')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Y6MEPfCRC-"
      },
      "source": [
        "#EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nWACJzvHyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095a32bc-97c6-49d8-f973-197c4c9b98fe"
      },
      "source": [
        "# da ignorare per lo studio 1\n",
        "result_base=model.evaluate(embedded_trainset,one_hot_train,batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET ORIGINARIO{result_base}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 3s 42ms/step - loss: 1.7612 - accuracy: 0.6811\n",
            "DATASET ORIGINARIO[1.7612053155899048, 0.6810740232467651]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjcdAwqeOi7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8c89c5a-74c1-4786-c8bc-643f98b7ee75"
      },
      "source": [
        "result_base=model.evaluate(embedded_test,one_hot_test,batch_size=best_params['batch_size'],)\n",
        "print(f'DATASET DEV{result_base}')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 1s 46ms/step - loss: 2.0741 - accuracy: 0.6925\n",
            "DATASET DEV[2.0740697383880615, 0.6924999952316284]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuaVK__WOjDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b8ea4f-0bf1-467a-dd21-29cbc2eed9d6"
      },
      "source": [
        "result_base=model.evaluate(embedded_sin,one_hot_sin,batch_size=best_params['batch_size'])\n",
        "print(f'DATASET SINONIMI{result_base}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 1s 41ms/step - loss: 2.4116 - accuracy: 0.6517\n",
            "DATASET SINONIMI[2.411626100540161, 0.6516666412353516]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JgLKE2bOjLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2b3e7b-cdbd-419f-bf0d-b1f49788f1c1"
      },
      "source": [
        "result_base=model.evaluate(embedded_emb,one_hot_emb,batch_size=best_params['batch_size'])\n",
        "print(f'DATASET EMBEDDING{result_base}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 1s 45ms/step - loss: 2.0096 - accuracy: 0.6892\n",
            "DATASET EMBEDDING[2.0095624923706055, 0.6891666650772095]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkCNsSHVOV8v",
        "outputId": "04aadca1-b93f-490d-9f5c-b667a77efc3f"
      },
      "source": [
        "# aggiunta per studio 2 eseguo l'evaluation rispetto al testset originale + testset embedding\n",
        "result_base=model.evaluate(embedded_test_study_1,one_hot_test_study_1,batch_size=best_params['batch_size'])\n",
        "print(f'DATASET TEST+TEST_EMBEDDING{result_base}')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 2s 42ms/step - loss: 2.0418 - accuracy: 0.6908\n",
            "DATASET TEST+TEST_EMBEDDING[2.041815996170044, 0.690833330154419]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}