{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nearby-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "healthy-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fourth-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greater-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_org = pd.read_json(path+'ATE_ABSITA_training_set/ate_absita_training.ndjson', lines=True)\n",
    "\n",
    "train_emb = pd.read_csv(path+'ATE_ABSITA_training_set/embedding.csv')\n",
    "\n",
    "dev = pd.concat([pd.read_json(path+'ATE_ABSITA_dev_set/ate_absita_dev.ndjson', lines=True),\n",
    "                 pd.read_csv(path+'ATE_ABSITA_dev_set/embedding.csv')],\n",
    "                ignore_index=True)\n",
    "\n",
    "test_org = pd.read_json(path+'ATE_ABSITA_test_set/ate_absita_gold.ndjson', lines=True)\n",
    "\n",
    "test_emb = pd.read_csv(path+'ATE_ABSITA_test_set/embedding.csv')\n",
    "\n",
    "\n",
    "data_sinonimi = pd.read_csv(path+\"ATE_ABSITA_test_set/sinonimi.csv\")\n",
    "data_embedding = pd.read_csv(path+\"ATE_ABSITA_test_set/embedding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "competent-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_study_1 = pd.concat([train_org, train_emb], ignore_index=True).sample(frac=1)\n",
    "test_study_1 = pd.concat([test_org, test_emb], ignore_index=True).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surprising-reservoir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains 6108 sentences\n",
      "Contains 218 sentences\n",
      "Contains 2400 sentences\n",
      "Contains 1200 sentences\n",
      "Contains 1200 sentences\n"
     ]
    }
   ],
   "source": [
    "train_study_1.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
    "dev.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
    "test_org.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
    "test_study_1.drop(columns=['id_sentence','polarities','aspects_position','aspects'], inplace=True)\n",
    "data_sinonimi.drop(columns=['polarities','aspects_position','aspects'], inplace=True)\n",
    "data_embedding.drop(columns=['polarities','aspects_position','aspects'], inplace=True)\n",
    "\n",
    "print(f'Contains {len(train_study_1)} sentences')\n",
    "print(f'Contains {len(dev)} sentences')\n",
    "print(f'Contains {len(test_study_1)} sentences')\n",
    "print(f'Contains {len(data_sinonimi)} sentences')\n",
    "print(f'Contains {len(data_embedding)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "according-revelation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN::\n",
      "pos    4300\n",
      "neg    1808\n",
      "Name: review_type, dtype: int64\n",
      "DEV::\n",
      "pos    172\n",
      "neg     46\n",
      "Name: review_type, dtype: int64\n",
      "TEST::\n",
      "pos    1714\n",
      "neg     686\n",
      "Name: review_type, dtype: int64\n",
      "SINONIMI::\n",
      "pos    857\n",
      "neg    343\n",
      "Name: review_type, dtype: int64\n",
      "EMBEDDING::\n",
      "pos    857\n",
      "neg    343\n",
      "Name: review_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_study_1[\"review_type\"] = train_study_1[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
    "dev[\"review_type\"] = dev[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
    "test_org[\"review_type\"] = test_org[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
    "test_study_1[\"review_type\"] = test_study_1[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
    "data_sinonimi[\"review_type\"] = data_sinonimi[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
    "data_embedding[\"review_type\"] = data_embedding[\"score\"].apply(lambda x: \"neg\" if x < 5 else \"pos\")\n",
    "\n",
    "print(f'TRAIN::\\n{train_study_1.review_type.value_counts()}')\n",
    "print(f'DEV::\\n{dev.review_type.value_counts()}')\n",
    "print(f'TEST::\\n{test_study_1.review_type.value_counts()}')\n",
    "print(f'SINONIMI::\\n{data_sinonimi.review_type.value_counts()}')\n",
    "print(f'EMBEDDING::\\n{data_embedding.review_type.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parental-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_study_1.drop(columns=['score'], inplace=True)\n",
    "dev.drop(columns=['score'], inplace=True)\n",
    "test_org.drop(columns=['score'], inplace=True)\n",
    "test_study_1.drop(columns=['score'], inplace=True)\n",
    "data_sinonimi.drop(columns=['score'], inplace=True)\n",
    "data_embedding.drop(columns=['score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "precious-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_text_to_word_sequence(sentence):\n",
    "    return keras.preprocessing.text.text_to_word_sequence(sentence,\n",
    "                                                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`\\'{|}~\\t\\n',\n",
    "                                                          lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-washington",
   "metadata": {},
   "source": [
    "# OneHotEncode delle frasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "light-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train = OneHotEncoder(sparse=False).fit_transform(\n",
    "        train_study_1.review_type.to_numpy().reshape(-1, 1))\n",
    "\n",
    "sentences = [my_text_to_word_sequence(sentence) for sentence in train_study_1['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fewer-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dev = OneHotEncoder(sparse=False).fit_transform(\n",
    "        dev.review_type.to_numpy().reshape(-1, 1))\n",
    "\n",
    "sentences_dev = [my_text_to_word_sequence(sentence) for sentence in dev['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "differential-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_test_org = OneHotEncoder(sparse=False).fit_transform(\n",
    "        test_org.review_type.to_numpy().reshape(-1, 1))\n",
    "\n",
    "sentences_test_org = [my_text_to_word_sequence(sentence) for sentence in test_org['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pretty-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_test = OneHotEncoder(sparse=False).fit_transform(\n",
    "        test_study_1.review_type.to_numpy().reshape(-1, 1))\n",
    "\n",
    "sentences_test = [my_text_to_word_sequence(sentence) for sentence in test_study_1['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "activated-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_sin = OneHotEncoder(sparse=False).fit_transform(\n",
    "        data_sinonimi.review_type.to_numpy().reshape(-1, 1))\n",
    "\n",
    "sentences_sin = [my_text_to_word_sequence(sentence) for sentence in data_sinonimi['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "radical-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_emb = OneHotEncoder(sparse=False).fit_transform(\n",
    "        data_embedding.review_type.to_numpy().reshape(-1, 1))\n",
    "\n",
    "sentences_emb = [my_text_to_word_sequence(sentence) for sentence in data_embedding['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "illegal-phone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il massimo è 86\n"
     ]
    }
   ],
   "source": [
    "max_index, max = (-1, -1)\n",
    "for i, sentence in enumerate(sentences):\n",
    "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
    "for i, sentence in enumerate(sentences_dev):\n",
    "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
    "for i, sentence in enumerate(sentences_test):\n",
    "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
    "for i, sentence in enumerate(sentences_sin):\n",
    "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
    "for i, sentence in enumerate(sentences_emb):\n",
    "  max_index, max = (i, len(sentence)) if len(sentence) > max else (max_index, max)\n",
    "\n",
    "\n",
    "print(f'Il massimo è {max}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-convertible",
   "metadata": {},
   "source": [
    "# Embedding delle frasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "antique-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+\"word2index.pkl\", 'rb') as output:\n",
    "  w2i = pickle.load(output)\n",
    "with open(path+\"embedding_matrix.pkl\", 'rb') as output:\n",
    "  embedding_matrix = pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "noted-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_trainset = np.zeros(shape=(len(sentences), max, 300))\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for j, word in enumerate(sentence):\n",
    "        try:\n",
    "            embedded_trainset[i, j, :] = embedding_matrix[w2i[word]]\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "invisible-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_devset = np.zeros(shape=(len(sentences_dev), max, 300))\n",
    "for i, sentence in enumerate(sentences_dev):\n",
    "    for j, word in enumerate(sentence):\n",
    "        try:\n",
    "            embedded_devset[i, j, :] = embedding_matrix[w2i[word]]\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "completed-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_testset_org = np.zeros(shape=(len(sentences_test_org), max, 300))\n",
    "for i, sentence in enumerate(sentences_test_org):\n",
    "    for j, word in enumerate(sentence):\n",
    "        try:\n",
    "            embedded_testset_org[i, j, :] = embedding_matrix[w2i[word]]\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "technological-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_testset = np.zeros(shape=(len(sentences_test), max, 300))\n",
    "for i, sentence in enumerate(sentences_test):\n",
    "    for j, word in enumerate(sentence):\n",
    "        try:\n",
    "            embedded_testset[i, j, :] = embedding_matrix[w2i[word]]\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "everyday-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_sin = np.zeros(shape=(len(sentences_sin), max, 300))\n",
    "for i, sentence in enumerate(sentences_sin):\n",
    "    for j, word in enumerate(sentence):\n",
    "        try:\n",
    "            embedded_sin[i, j, :] = embedding_matrix[w2i[word]]\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "advance-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_emb = np.zeros(shape=(len(sentences_emb), max, 300))\n",
    "for i, sentence in enumerate(sentences_emb):\n",
    "    for j, word in enumerate(sentence):\n",
    "        try:\n",
    "            embedded_emb[i, j, :] = embedding_matrix[w2i[word]]\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-neutral",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "exempt-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optuna.load_study(study_name=\"ATE\", storage=\"sqlite:///\"+path+\"optuna_ATE_studio_0.db\").best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "crude-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input(shape=(max, 300)))\n",
    "model.add(keras.layers.Bidirectional(layer=keras.layers.LSTM(units=best_params[\"units\"],\n",
    "                                                             recurrent_dropout=best_params[\"dropout\"],\n",
    "                                                             activation='tanh')))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=keras.optimizers.Adam(0.001),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "material-slave",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "112/112 [==============================] - 19s 133ms/step - loss: 0.6006 - accuracy: 0.7065 - val_loss: 0.4913 - val_accuracy: 0.8119\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 14s 128ms/step - loss: 0.5316 - accuracy: 0.7376 - val_loss: 0.4844 - val_accuracy: 0.7844\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 14s 127ms/step - loss: 0.4931 - accuracy: 0.7635 - val_loss: 0.4240 - val_accuracy: 0.8486\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 15s 134ms/step - loss: 0.4640 - accuracy: 0.7866 - val_loss: 0.4940 - val_accuracy: 0.7523\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 15s 136ms/step - loss: 0.4623 - accuracy: 0.7887 - val_loss: 0.4119 - val_accuracy: 0.8257\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.4194 - accuracy: 0.8103 - val_loss: 0.4225 - val_accuracy: 0.8349\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 15s 136ms/step - loss: 0.3992 - accuracy: 0.8207 - val_loss: 0.4014 - val_accuracy: 0.8303\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.3928 - accuracy: 0.8327 - val_loss: 0.4095 - val_accuracy: 0.8028\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.3440 - accuracy: 0.8551 - val_loss: 0.4074 - val_accuracy: 0.8486\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 15s 134ms/step - loss: 0.3112 - accuracy: 0.8665 - val_loss: 0.4408 - val_accuracy: 0.8119\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.2743 - accuracy: 0.8899 - val_loss: 0.4147 - val_accuracy: 0.8578\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.2633 - accuracy: 0.8913 - val_loss: 0.5515 - val_accuracy: 0.8211\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 15s 134ms/step - loss: 0.2289 - accuracy: 0.9080 - val_loss: 0.5634 - val_accuracy: 0.7798\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.2197 - accuracy: 0.9089 - val_loss: 0.6505 - val_accuracy: 0.7706\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.1720 - accuracy: 0.9301 - val_loss: 0.6271 - val_accuracy: 0.8028\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.1607 - accuracy: 0.9366 - val_loss: 0.6394 - val_accuracy: 0.8073\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.1399 - accuracy: 0.9474 - val_loss: 0.6394 - val_accuracy: 0.7706\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.1342 - accuracy: 0.9480 - val_loss: 0.7064 - val_accuracy: 0.7890\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.1424 - accuracy: 0.9394 - val_loss: 0.7942 - val_accuracy: 0.8119\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 15s 134ms/step - loss: 0.1043 - accuracy: 0.9610 - val_loss: 0.6947 - val_accuracy: 0.8165\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 15s 135ms/step - loss: 0.0925 - accuracy: 0.9683 - val_loss: 0.9702 - val_accuracy: 0.7936\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(embedded_trainset,\n",
    "                   one_hot_train,\n",
    "                   validation_data=(embedded_devset, one_hot_dev),\n",
    "                   epochs=100,\n",
    "                   batch_size=best_params[\"batch_size\"],\n",
    "                   callbacks=[keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                                            patience=10,\n",
    "                                                            restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "boring-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('ATE_w_studio2_005.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-baghdad",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "available-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-celtic",
   "metadata": {},
   "source": [
    "## DATASET ORIGINARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dangerous-firmware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 3s 27ms/step - loss: 0.2602 - accuracy: 0.8856\n",
      "DATASET ORIGINARIO[0.26019465923309326, 0.8855599164962769]\n"
     ]
    }
   ],
   "source": [
    "result_base = model.evaluate(embedded_trainset,one_hot_train,batch_size=best_params['batch_size'])\n",
    "print(f'DATASET ORIGINARIO{result_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "clear-noise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\tP\tN\n",
      "\n",
      "P\t1162\t646\n",
      "\n",
      "N\t53\t4247\n",
      "\n",
      "\n",
      "FSCORE:\t0.9239638855651039\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(embedded_trainset, batch_size=best_params['batch_size'])\n",
    "cm = confusion_matrix(one_hot_train.argmax(axis=1), pred.argmax(axis=1))\n",
    "fscore = f1_score(one_hot_train.argmax(axis=1), pred.argmax(axis=1))\n",
    "\n",
    "print(f\"\"\"Confusion Matrix:\n",
    "\\tP\\tN\\n\n",
    "P\\t{cm[0][0]}\\t{cm[0][1]}\\n\n",
    "N\\t{cm[1][0]}\\t{cm[1][1]}\"\"\")\n",
    "\n",
    "print(f'\\n\\nFSCORE:\\t{fscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-croatia",
   "metadata": {},
   "source": [
    "## TESTSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "recovered-edgar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 27ms/step - loss: 0.6369 - accuracy: 0.7633\n",
      "DATASET TEST[0.6368718147277832, 0.7633333206176758]\n"
     ]
    }
   ],
   "source": [
    "result_base=model.evaluate(embedded_testset,one_hot_test,batch_size=best_params['batch_size'])\n",
    "print(f'DATASET TEST{result_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "turkish-update",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\tP\tN\n",
      "\n",
      "P\t270\t416\n",
      "\n",
      "N\t152\t1562\n",
      "\n",
      "\n",
      "FSCORE:\t0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(embedded_testset, batch_size=best_params['batch_size'])\n",
    "cm = confusion_matrix(one_hot_test.argmax(axis=1), pred.argmax(axis=1))\n",
    "fscore = f1_score(one_hot_test.argmax(axis=1), pred.argmax(axis=1))\n",
    "\n",
    "print(f\"\"\"Confusion Matrix:\n",
    "\\tP\\tN\\n\n",
    "P\\t{cm[0][0]}\\t{cm[0][1]}\\n\n",
    "N\\t{cm[1][0]}\\t{cm[1][1]}\"\"\")\n",
    "\n",
    "print(f'\\n\\nFSCORE:\\t{fscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-initial",
   "metadata": {},
   "source": [
    "## TESTSET ORIGINARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "resistant-century",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6395 - accuracy: 0.7592\n",
      "DATASET TEST[0.6394989490509033, 0.7591666579246521]\n"
     ]
    }
   ],
   "source": [
    "result_base=model.evaluate(embedded_testset_org,one_hot_test_org,batch_size=best_params['batch_size'])\n",
    "print(f'DATASET TEST{result_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "convertible-diameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\tP\tN\n",
      "\n",
      "P\t132\t211\n",
      "\n",
      "N\t78\t779\n",
      "\n",
      "\n",
      "FSCORE:\t0.8435300487276665\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(embedded_testset_org, batch_size=best_params['batch_size'])\n",
    "cm = confusion_matrix(one_hot_test_org.argmax(axis=1), pred.argmax(axis=1))\n",
    "fscore = f1_score(one_hot_test_org.argmax(axis=1), pred.argmax(axis=1))\n",
    "\n",
    "print(f\"\"\"Confusion Matrix:\n",
    "\\tP\\tN\\n\n",
    "P\\t{cm[0][0]}\\t{cm[0][1]}\\n\n",
    "N\\t{cm[1][0]}\\t{cm[1][1]}\"\"\")\n",
    "\n",
    "print(f'\\n\\nFSCORE:\\t{fscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-template",
   "metadata": {},
   "source": [
    "## DATASET SINONIMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "established-ideal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6479 - accuracy: 0.7542\n",
      "DATASET SINONIMI[0.6478922367095947, 0.7541666626930237]\n"
     ]
    }
   ],
   "source": [
    "result_base=model.evaluate(embedded_sin,one_hot_sin,batch_size=best_params['batch_size'])\n",
    "print(f'DATASET SINONIMI{result_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "female-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\tP\tN\n",
      "\n",
      "P\t129\t214\n",
      "\n",
      "N\t81\t776\n",
      "\n",
      "\n",
      "FSCORE:\t0.8402815376285869\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(embedded_sin, batch_size=best_params['batch_size'])\n",
    "cm = confusion_matrix(one_hot_sin.argmax(axis=1), pred.argmax(axis=1))\n",
    "fscore = f1_score(one_hot_sin.argmax(axis=1), pred.argmax(axis=1))\n",
    "\n",
    "print(f\"\"\"Confusion Matrix:\n",
    "\\tP\\tN\\n\n",
    "P\\t{cm[0][0]}\\t{cm[0][1]}\\n\n",
    "N\\t{cm[1][0]}\\t{cm[1][1]}\"\"\")\n",
    "\n",
    "print(f'\\n\\nFSCORE:\\t{fscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-spider",
   "metadata": {},
   "source": [
    "## DATASET EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dynamic-valve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 27ms/step - loss: 0.6342 - accuracy: 0.7675\n",
      "DATASET EMBEDDING[0.6342445611953735, 0.7674999833106995]\n"
     ]
    }
   ],
   "source": [
    "result_base=model.evaluate(embedded_emb,one_hot_emb,batch_size=best_params['batch_size'])\n",
    "print(f'DATASET EMBEDDING{result_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "toxic-husband",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\tP\tN\n",
      "\n",
      "P\t138\t205\n",
      "\n",
      "N\t74\t783\n",
      "\n",
      "\n",
      "FSCORE:\t0.848780487804878\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(embedded_emb, batch_size=best_params['batch_size'])\n",
    "cm = confusion_matrix(one_hot_emb.argmax(axis=1), pred.argmax(axis=1))\n",
    "fscore = f1_score(one_hot_emb.argmax(axis=1), pred.argmax(axis=1))\n",
    "\n",
    "print(f\"\"\"Confusion Matrix:\n",
    "\\tP\\tN\\n\n",
    "P\\t{cm[0][0]}\\t{cm[0][1]}\\n\n",
    "N\\t{cm[1][0]}\\t{cm[1][1]}\"\"\")\n",
    "\n",
    "print(f'\\n\\nFSCORE:\\t{fscore}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
